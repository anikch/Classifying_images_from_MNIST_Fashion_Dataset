{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classifying images from MNIST Fashion Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "koXYthpwwD3a",
        "UXhoXcRgwO8i",
        "MxNBZZwqwV9Z",
        "2bomvkk5wbBj"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOHRBrR+qljBkBCaytHFoGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anikch/Classifying_images_from_MNIST_Fashion_Dataset/blob/main/Classifying_images_from_MNIST_Fashion_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5xqGI4Tnc-E"
      },
      "source": [
        "# Importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfw2FdfBnpYc",
        "outputId": "4f622450-2061-442b-883a-7e857fd00f43"
      },
      "source": [
        "#Check tensorflow version\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1aLtPtJvNcS"
      },
      "source": [
        "## Loading and checking data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UtMJt5To2ay",
        "outputId": "f11faf94-6f7c-42ce-9f4d-8fe6b7a389c5"
      },
      "source": [
        "# Loading fashion_mnist dataset\n",
        "(X_train, y_train), (X_test, y_test)= fashion_mnist.load_data()\n",
        "\n",
        "# Checking shape of train test dataset\n",
        "X_train.shape, X_test.shape, y_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (10000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al2d82h1riq-",
        "outputId": "54f9a8fc-be8e-4cc2-adb1-6ccb7162fd1e"
      },
      "source": [
        "# Checking arbitary image\n",
        "plt.imshow(X_train[10,:,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7e3c5def10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpY1tm74zR8Z"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIyUesk2vXtR"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3K-v7B-qt7B"
      },
      "source": [
        "# Converting data into float32 to use 32-bit precision\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7UhXf3Orb_z"
      },
      "source": [
        "# Normalizing data (actual value - min / max - min)\n",
        "# Pixel value ranges between 0-255\n",
        "X_train_norm=  X_train/ 255.0\n",
        "X_test_norm= X_test/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70Dfh4hvusbd",
        "outputId": "9b6bdf1b-a277-4645-d8e1-e8e71f49bbda"
      },
      "source": [
        "# Reshaping data\n",
        "X_train_norm= X_train_norm.reshape(X_train_norm.shape[0], -1)\n",
        "X_test_norm= X_test_norm.reshape(X_test_norm.shape[0], -1)\n",
        "\n",
        "# Checking final shape\n",
        "X_train_norm.shape, X_test_norm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qhUY4PUv2Uy",
        "outputId": "8a900fdb-1b9f-4da4-cdb4-665a0143ed2f"
      },
      "source": [
        "# Checking unique categories in y_test and y_train\n",
        "np.unique(y_train), np.unique(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
              " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XPqNgDcvhVB"
      },
      "source": [
        "# Performing One-hot encoding of 10 labels\n",
        "y_train_cat= tf.keras.utils.to_categorical(y_train, 10) \n",
        "y_test_cat= tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQIC2RVBQdU"
      },
      "source": [
        "## Model Building and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nFO0Y-6vyU2"
      },
      "source": [
        "### 1. Building Perceptron with softmax activation and SGD optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uHgApxTwb0p",
        "outputId": "5ee20dfe-4af8-42b6-b459-fbc7a3359f9d"
      },
      "source": [
        "# Building Perceptron with softmax activation and SGD optimizer\n",
        "tf.random.set_seed(42)\n",
        "model= tf.keras.Sequential(name= 'perceptron_1')\n",
        "model.add(tf.keras.layers.Dense(10, input_shape= (X_train_norm.shape[1],), activation= 'softmax', name= 'dense_layer1'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(optimizer= 'sgd', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history= model.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 3s 3ms/step - loss: 1.2154 - accuracy: 0.6335 - val_loss: 0.8956 - val_accuracy: 0.7179\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.8232 - accuracy: 0.7369 - val_loss: 0.7580 - val_accuracy: 0.7579\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.7292 - accuracy: 0.7685 - val_loss: 0.6932 - val_accuracy: 0.7783\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6786 - accuracy: 0.7836 - val_loss: 0.6544 - val_accuracy: 0.7896\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6447 - accuracy: 0.7947 - val_loss: 0.6270 - val_accuracy: 0.7962\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6203 - accuracy: 0.8009 - val_loss: 0.6067 - val_accuracy: 0.8019\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.6012 - accuracy: 0.8070 - val_loss: 0.5907 - val_accuracy: 0.8065\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5858 - accuracy: 0.8106 - val_loss: 0.5794 - val_accuracy: 0.8097\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5732 - accuracy: 0.8147 - val_loss: 0.5669 - val_accuracy: 0.8143\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5625 - accuracy: 0.8169 - val_loss: 0.5574 - val_accuracy: 0.8159\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5531 - accuracy: 0.8197 - val_loss: 0.5493 - val_accuracy: 0.8174\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5452 - accuracy: 0.8222 - val_loss: 0.5435 - val_accuracy: 0.8177\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5380 - accuracy: 0.8238 - val_loss: 0.5363 - val_accuracy: 0.8207\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5318 - accuracy: 0.8257 - val_loss: 0.5307 - val_accuracy: 0.8218\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5261 - accuracy: 0.8270 - val_loss: 0.5258 - val_accuracy: 0.8229\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5208 - accuracy: 0.8286 - val_loss: 0.5214 - val_accuracy: 0.8230\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5162 - accuracy: 0.8299 - val_loss: 0.5166 - val_accuracy: 0.8249\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5119 - accuracy: 0.8305 - val_loss: 0.5128 - val_accuracy: 0.8263\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.8321 - val_loss: 0.5092 - val_accuracy: 0.8263\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5041 - accuracy: 0.8328 - val_loss: 0.5072 - val_accuracy: 0.8278\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.5008 - accuracy: 0.8335 - val_loss: 0.5031 - val_accuracy: 0.8285\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4975 - accuracy: 0.8348 - val_loss: 0.5005 - val_accuracy: 0.8282\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4945 - accuracy: 0.8353 - val_loss: 0.4977 - val_accuracy: 0.8296\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4916 - accuracy: 0.8361 - val_loss: 0.4980 - val_accuracy: 0.8292\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4888 - accuracy: 0.8369 - val_loss: 0.4926 - val_accuracy: 0.8322\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4864 - accuracy: 0.8377 - val_loss: 0.4912 - val_accuracy: 0.8328\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.8384 - val_loss: 0.4888 - val_accuracy: 0.8321\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4818 - accuracy: 0.8395 - val_loss: 0.4864 - val_accuracy: 0.8327\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4796 - accuracy: 0.8393 - val_loss: 0.4841 - val_accuracy: 0.8332\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4776 - accuracy: 0.8400 - val_loss: 0.4828 - val_accuracy: 0.8334\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4757 - accuracy: 0.8406 - val_loss: 0.4814 - val_accuracy: 0.8351\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4737 - accuracy: 0.8409 - val_loss: 0.4799 - val_accuracy: 0.8356\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4721 - accuracy: 0.8423 - val_loss: 0.4779 - val_accuracy: 0.8370\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4702 - accuracy: 0.8418 - val_loss: 0.4770 - val_accuracy: 0.8374\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4686 - accuracy: 0.8428 - val_loss: 0.4753 - val_accuracy: 0.8370\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4671 - accuracy: 0.8431 - val_loss: 0.4737 - val_accuracy: 0.8377\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4656 - accuracy: 0.8439 - val_loss: 0.4729 - val_accuracy: 0.8374\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4640 - accuracy: 0.8443 - val_loss: 0.4714 - val_accuracy: 0.8377\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.8443 - val_loss: 0.4698 - val_accuracy: 0.8388\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4614 - accuracy: 0.8456 - val_loss: 0.4684 - val_accuracy: 0.8386\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4600 - accuracy: 0.8453 - val_loss: 0.4682 - val_accuracy: 0.8394\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4589 - accuracy: 0.8459 - val_loss: 0.4667 - val_accuracy: 0.8397\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4576 - accuracy: 0.8457 - val_loss: 0.4652 - val_accuracy: 0.8413\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4563 - accuracy: 0.8464 - val_loss: 0.4639 - val_accuracy: 0.8410\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4552 - accuracy: 0.8462 - val_loss: 0.4636 - val_accuracy: 0.8409\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4542 - accuracy: 0.8470 - val_loss: 0.4625 - val_accuracy: 0.8408\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4532 - accuracy: 0.8474 - val_loss: 0.4615 - val_accuracy: 0.8430\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4521 - accuracy: 0.8474 - val_loss: 0.4602 - val_accuracy: 0.8432\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4511 - accuracy: 0.8476 - val_loss: 0.4605 - val_accuracy: 0.8424\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4501 - accuracy: 0.8485 - val_loss: 0.4584 - val_accuracy: 0.8439\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.8489 - val_loss: 0.4576 - val_accuracy: 0.8442\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4482 - accuracy: 0.8489 - val_loss: 0.4582 - val_accuracy: 0.8433\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4473 - accuracy: 0.8483 - val_loss: 0.4562 - val_accuracy: 0.8444\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4464 - accuracy: 0.8500 - val_loss: 0.4571 - val_accuracy: 0.8440\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.8492 - val_loss: 0.4547 - val_accuracy: 0.8438\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4448 - accuracy: 0.8501 - val_loss: 0.4542 - val_accuracy: 0.8449\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8506 - val_loss: 0.4533 - val_accuracy: 0.8443\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4431 - accuracy: 0.8509 - val_loss: 0.4535 - val_accuracy: 0.8432\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4425 - accuracy: 0.8507 - val_loss: 0.4520 - val_accuracy: 0.8448\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8511 - val_loss: 0.4521 - val_accuracy: 0.8447\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4409 - accuracy: 0.8508 - val_loss: 0.4510 - val_accuracy: 0.8459\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4402 - accuracy: 0.8515 - val_loss: 0.4519 - val_accuracy: 0.8439\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.8516 - val_loss: 0.4499 - val_accuracy: 0.8448\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4387 - accuracy: 0.8516 - val_loss: 0.4500 - val_accuracy: 0.8447\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4380 - accuracy: 0.8515 - val_loss: 0.4485 - val_accuracy: 0.8470\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4374 - accuracy: 0.8520 - val_loss: 0.4485 - val_accuracy: 0.8469\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4369 - accuracy: 0.8523 - val_loss: 0.4475 - val_accuracy: 0.8457\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4363 - accuracy: 0.8534 - val_loss: 0.4475 - val_accuracy: 0.8452\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4355 - accuracy: 0.8526 - val_loss: 0.4473 - val_accuracy: 0.8461\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4349 - accuracy: 0.8531 - val_loss: 0.4460 - val_accuracy: 0.8462\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4343 - accuracy: 0.8533 - val_loss: 0.4460 - val_accuracy: 0.8470\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4338 - accuracy: 0.8528 - val_loss: 0.4452 - val_accuracy: 0.8460\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4331 - accuracy: 0.8531 - val_loss: 0.4445 - val_accuracy: 0.8476\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4326 - accuracy: 0.8531 - val_loss: 0.4455 - val_accuracy: 0.8483\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4321 - accuracy: 0.8535 - val_loss: 0.4441 - val_accuracy: 0.8475\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8540 - val_loss: 0.4445 - val_accuracy: 0.8482\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4310 - accuracy: 0.8539 - val_loss: 0.4428 - val_accuracy: 0.8478\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4304 - accuracy: 0.8544 - val_loss: 0.4439 - val_accuracy: 0.8477\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4299 - accuracy: 0.8545 - val_loss: 0.4421 - val_accuracy: 0.8484\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4293 - accuracy: 0.8545 - val_loss: 0.4418 - val_accuracy: 0.8485\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4290 - accuracy: 0.8548 - val_loss: 0.4414 - val_accuracy: 0.8483\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4285 - accuracy: 0.8544 - val_loss: 0.4410 - val_accuracy: 0.8493\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4281 - accuracy: 0.8551 - val_loss: 0.4403 - val_accuracy: 0.8491\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4276 - accuracy: 0.8552 - val_loss: 0.4399 - val_accuracy: 0.8484\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4271 - accuracy: 0.8554 - val_loss: 0.4403 - val_accuracy: 0.8491\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4268 - accuracy: 0.8553 - val_loss: 0.4396 - val_accuracy: 0.8492\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4262 - accuracy: 0.8559 - val_loss: 0.4393 - val_accuracy: 0.8493\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4258 - accuracy: 0.8553 - val_loss: 0.4387 - val_accuracy: 0.8492\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8554 - val_loss: 0.4390 - val_accuracy: 0.8499\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4248 - accuracy: 0.8558 - val_loss: 0.4384 - val_accuracy: 0.8492\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4245 - accuracy: 0.8560 - val_loss: 0.4383 - val_accuracy: 0.8500\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4240 - accuracy: 0.8561 - val_loss: 0.4375 - val_accuracy: 0.8497\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4237 - accuracy: 0.8560 - val_loss: 0.4375 - val_accuracy: 0.8499\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4232 - accuracy: 0.8565 - val_loss: 0.4375 - val_accuracy: 0.8509\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4229 - accuracy: 0.8563 - val_loss: 0.4372 - val_accuracy: 0.8510\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4225 - accuracy: 0.8570 - val_loss: 0.4368 - val_accuracy: 0.8507\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8572 - val_loss: 0.4360 - val_accuracy: 0.8507\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4217 - accuracy: 0.8569 - val_loss: 0.4358 - val_accuracy: 0.8501\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4213 - accuracy: 0.8574 - val_loss: 0.4365 - val_accuracy: 0.8499\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4211 - accuracy: 0.8566 - val_loss: 0.4363 - val_accuracy: 0.8509\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVLfIFHEHuUv",
        "outputId": "034f75af-3d5c-4d86-ff32-db6e91a9276c"
      },
      "source": [
        "# Checking model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"perceptron_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "137J3bLHH0PO",
        "outputId": "c136986b-cb20-4a20-e45b-0c1ae8d928c8"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.8375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4632628560066223, 0.8374999761581421]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "1kqThqiPIce_",
        "outputId": "a3c751be-d9ce-4097-8aff-95b0148e8075"
      },
      "source": [
        "# Plotting accuracy for different epochs\n",
        "plt.figure(figsize= [8,5])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Plot for model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "RjK6RoDHJr7x",
        "outputId": "11401bbe-87b7-47de-a1e8-bdc1085ab42c"
      },
      "source": [
        "# Plotting loss for different epochs\n",
        "plt.figure(figsize= [8,5])\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Plot for model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkPh_7cVH34G"
      },
      "source": [
        "Using perceptron we have got testing accuracy of .84 and training accuracy of .86. Now, let's check with a Multilayer Perceptron with one hidden layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxoCPhB8v5_z"
      },
      "source": [
        "### 2. Building model with one hidden layer of 128 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQK8UGKvGUz7",
        "outputId": "758aeff7-886e-4b12-e2e5-1ccaf83a426f"
      },
      "source": [
        "# Building model with one hidden layer of 128 neurons\n",
        "tf.random.set_seed(42)\n",
        "model1= tf.keras.Sequential(name= 'mlp_1')\n",
        "model1.add(tf.keras.layers.Dense(128, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model1.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer2'))\n",
        "\n",
        "# Compiling the model\n",
        "model1.compile(optimizer= 'sgd', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history1= model1.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.1473 - accuracy: 0.6556 - val_loss: 0.8069 - val_accuracy: 0.7442\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7310 - accuracy: 0.7668 - val_loss: 0.6702 - val_accuracy: 0.7828\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6366 - accuracy: 0.7946 - val_loss: 0.6068 - val_accuracy: 0.7999\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5870 - accuracy: 0.8082 - val_loss: 0.5696 - val_accuracy: 0.8120\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5546 - accuracy: 0.8171 - val_loss: 0.5469 - val_accuracy: 0.8173\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5317 - accuracy: 0.8229 - val_loss: 0.5241 - val_accuracy: 0.8242\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5137 - accuracy: 0.8282 - val_loss: 0.5107 - val_accuracy: 0.8262\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4996 - accuracy: 0.8324 - val_loss: 0.5005 - val_accuracy: 0.8286\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4878 - accuracy: 0.8350 - val_loss: 0.4885 - val_accuracy: 0.8332\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4782 - accuracy: 0.8384 - val_loss: 0.4821 - val_accuracy: 0.8332\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4695 - accuracy: 0.8404 - val_loss: 0.4725 - val_accuracy: 0.8368\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4622 - accuracy: 0.8417 - val_loss: 0.4729 - val_accuracy: 0.8342\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4554 - accuracy: 0.8447 - val_loss: 0.4635 - val_accuracy: 0.8415\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4497 - accuracy: 0.8468 - val_loss: 0.4556 - val_accuracy: 0.8432\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4439 - accuracy: 0.8478 - val_loss: 0.4514 - val_accuracy: 0.8440\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4389 - accuracy: 0.8505 - val_loss: 0.4467 - val_accuracy: 0.8442\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4345 - accuracy: 0.8516 - val_loss: 0.4425 - val_accuracy: 0.8472\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.8527 - val_loss: 0.4388 - val_accuracy: 0.8482\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.8533 - val_loss: 0.4364 - val_accuracy: 0.8486\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4220 - accuracy: 0.8553 - val_loss: 0.4361 - val_accuracy: 0.8482\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8571 - val_loss: 0.4292 - val_accuracy: 0.8527\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8581 - val_loss: 0.4271 - val_accuracy: 0.8510\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4121 - accuracy: 0.8581 - val_loss: 0.4274 - val_accuracy: 0.8512\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4090 - accuracy: 0.8593 - val_loss: 0.4243 - val_accuracy: 0.8547\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8615 - val_loss: 0.4184 - val_accuracy: 0.8564\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4030 - accuracy: 0.8623 - val_loss: 0.4199 - val_accuracy: 0.8563\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.4003 - accuracy: 0.8632 - val_loss: 0.4133 - val_accuracy: 0.8581\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3978 - accuracy: 0.8637 - val_loss: 0.4122 - val_accuracy: 0.8579\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3949 - accuracy: 0.8645 - val_loss: 0.4100 - val_accuracy: 0.8587\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.8647 - val_loss: 0.4078 - val_accuracy: 0.8580\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3905 - accuracy: 0.8661 - val_loss: 0.4071 - val_accuracy: 0.8611\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3877 - accuracy: 0.8667 - val_loss: 0.4048 - val_accuracy: 0.8610\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3857 - accuracy: 0.8674 - val_loss: 0.4039 - val_accuracy: 0.8619\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3834 - accuracy: 0.8682 - val_loss: 0.4037 - val_accuracy: 0.8613\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3813 - accuracy: 0.8680 - val_loss: 0.4011 - val_accuracy: 0.8636\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3794 - accuracy: 0.8697 - val_loss: 0.4068 - val_accuracy: 0.8577\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8703 - val_loss: 0.3965 - val_accuracy: 0.8652\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3754 - accuracy: 0.8719 - val_loss: 0.3963 - val_accuracy: 0.8653\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3733 - accuracy: 0.8727 - val_loss: 0.3935 - val_accuracy: 0.8652\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8721 - val_loss: 0.3922 - val_accuracy: 0.8645\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3699 - accuracy: 0.8723 - val_loss: 0.3957 - val_accuracy: 0.8633\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3683 - accuracy: 0.8724 - val_loss: 0.3916 - val_accuracy: 0.8649\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3666 - accuracy: 0.8738 - val_loss: 0.3925 - val_accuracy: 0.8636\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8731 - val_loss: 0.3875 - val_accuracy: 0.8661\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3631 - accuracy: 0.8746 - val_loss: 0.3866 - val_accuracy: 0.8668\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8749 - val_loss: 0.3866 - val_accuracy: 0.8671\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8758 - val_loss: 0.3858 - val_accuracy: 0.8650\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8758 - val_loss: 0.3823 - val_accuracy: 0.8670\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3576 - accuracy: 0.8769 - val_loss: 0.3817 - val_accuracy: 0.8668\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3558 - accuracy: 0.8776 - val_loss: 0.3817 - val_accuracy: 0.8691\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3543 - accuracy: 0.8780 - val_loss: 0.3792 - val_accuracy: 0.8695\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8778 - val_loss: 0.3792 - val_accuracy: 0.8702\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3516 - accuracy: 0.8774 - val_loss: 0.3795 - val_accuracy: 0.8698\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8789 - val_loss: 0.3788 - val_accuracy: 0.8683\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3487 - accuracy: 0.8790 - val_loss: 0.3765 - val_accuracy: 0.8691\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3476 - accuracy: 0.8798 - val_loss: 0.3757 - val_accuracy: 0.8692\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3459 - accuracy: 0.8806 - val_loss: 0.3745 - val_accuracy: 0.8698\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3448 - accuracy: 0.8814 - val_loss: 0.3751 - val_accuracy: 0.8702\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3436 - accuracy: 0.8801 - val_loss: 0.3729 - val_accuracy: 0.8708\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3423 - accuracy: 0.8815 - val_loss: 0.3749 - val_accuracy: 0.8702\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8813 - val_loss: 0.3713 - val_accuracy: 0.8720\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3397 - accuracy: 0.8820 - val_loss: 0.3746 - val_accuracy: 0.8689\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3386 - accuracy: 0.8821 - val_loss: 0.3720 - val_accuracy: 0.8711\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3373 - accuracy: 0.8826 - val_loss: 0.3703 - val_accuracy: 0.8709\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3359 - accuracy: 0.8838 - val_loss: 0.3677 - val_accuracy: 0.8707\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3352 - accuracy: 0.8831 - val_loss: 0.3691 - val_accuracy: 0.8729\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3341 - accuracy: 0.8838 - val_loss: 0.3664 - val_accuracy: 0.8722\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3332 - accuracy: 0.8842 - val_loss: 0.3699 - val_accuracy: 0.8701\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3317 - accuracy: 0.8843 - val_loss: 0.3664 - val_accuracy: 0.8723\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8852 - val_loss: 0.3641 - val_accuracy: 0.8730\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3292 - accuracy: 0.8853 - val_loss: 0.3656 - val_accuracy: 0.8725\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8868 - val_loss: 0.3641 - val_accuracy: 0.8726\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3271 - accuracy: 0.8862 - val_loss: 0.3617 - val_accuracy: 0.8738\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8854 - val_loss: 0.3660 - val_accuracy: 0.8722\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3253 - accuracy: 0.8868 - val_loss: 0.3641 - val_accuracy: 0.8737\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8872 - val_loss: 0.3644 - val_accuracy: 0.8715\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3231 - accuracy: 0.8878 - val_loss: 0.3588 - val_accuracy: 0.8735\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3220 - accuracy: 0.8876 - val_loss: 0.3647 - val_accuracy: 0.8713\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3212 - accuracy: 0.8877 - val_loss: 0.3590 - val_accuracy: 0.8765\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3201 - accuracy: 0.8893 - val_loss: 0.3582 - val_accuracy: 0.8764\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.8885 - val_loss: 0.3568 - val_accuracy: 0.8765\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8890 - val_loss: 0.3582 - val_accuracy: 0.8740\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3182 - accuracy: 0.8885 - val_loss: 0.3549 - val_accuracy: 0.8763\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3165 - accuracy: 0.8891 - val_loss: 0.3547 - val_accuracy: 0.8763\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3157 - accuracy: 0.8898 - val_loss: 0.3555 - val_accuracy: 0.8751\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3146 - accuracy: 0.8900 - val_loss: 0.3558 - val_accuracy: 0.8756\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3134 - accuracy: 0.8905 - val_loss: 0.3541 - val_accuracy: 0.8774\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3129 - accuracy: 0.8909 - val_loss: 0.3539 - val_accuracy: 0.8761\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.8906 - val_loss: 0.3548 - val_accuracy: 0.8758\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3103 - accuracy: 0.8914 - val_loss: 0.3553 - val_accuracy: 0.8765\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3102 - accuracy: 0.8913 - val_loss: 0.3518 - val_accuracy: 0.8786\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3094 - accuracy: 0.8922 - val_loss: 0.3510 - val_accuracy: 0.8785\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3081 - accuracy: 0.8915 - val_loss: 0.3504 - val_accuracy: 0.8783\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3070 - accuracy: 0.8923 - val_loss: 0.3518 - val_accuracy: 0.8771\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3063 - accuracy: 0.8932 - val_loss: 0.3506 - val_accuracy: 0.8771\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.8935 - val_loss: 0.3541 - val_accuracy: 0.8749\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3050 - accuracy: 0.8932 - val_loss: 0.3496 - val_accuracy: 0.8781\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3036 - accuracy: 0.8935 - val_loss: 0.3491 - val_accuracy: 0.8776\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3029 - accuracy: 0.8934 - val_loss: 0.3507 - val_accuracy: 0.8772\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3023 - accuracy: 0.8942 - val_loss: 0.3491 - val_accuracy: 0.8771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNBzxNPPILWn",
        "outputId": "8a3d6798-8f50-4a5a-c9f1-6793d955eddb"
      },
      "source": [
        "# Checking model summary\n",
        "model1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAWI3NhsINxu",
        "outputId": "f8c38e47-8a08-498b-a1b6-24b00cdeccb4"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model1.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3722 - accuracy: 0.8684\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3721666634082794, 0.868399977684021]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mRS3QPqN7Co"
      },
      "source": [
        "Validation and testing accuracy both have increased and both losses have decreased from our previous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bz1AwJGFv_Hr"
      },
      "source": [
        "### 3. Building Multi-layer Perceptron with Dropout Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lL2qIi7IInvo",
        "outputId": "f84428af-5a4d-490a-b41d-7499545dba50"
      },
      "source": [
        "# Building Multi-layer Perceptron with Dropout Normalization\n",
        "tf.random.set_seed(42)\n",
        "model2= tf.keras.Sequential(name= 'mlp_2')\n",
        "model2.add(tf.keras.layers.Dense(128, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model2.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer1'))\n",
        "model2.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer2'))\n",
        "\n",
        "# Compiling the model\n",
        "model2.compile(optimizer= 'sgd', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history2= model2.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 1.2609 - accuracy: 0.5895 - val_loss: 0.8416 - val_accuracy: 0.7333\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.8404 - accuracy: 0.7224 - val_loss: 0.6998 - val_accuracy: 0.7773\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7376 - accuracy: 0.7543 - val_loss: 0.6372 - val_accuracy: 0.7917\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6769 - accuracy: 0.7742 - val_loss: 0.5965 - val_accuracy: 0.8058\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6354 - accuracy: 0.7865 - val_loss: 0.5679 - val_accuracy: 0.8127\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6091 - accuracy: 0.7959 - val_loss: 0.5482 - val_accuracy: 0.8195\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5862 - accuracy: 0.8056 - val_loss: 0.5312 - val_accuracy: 0.8243\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5683 - accuracy: 0.8095 - val_loss: 0.5184 - val_accuracy: 0.8267\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.8144 - val_loss: 0.5078 - val_accuracy: 0.8311\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5422 - accuracy: 0.8160 - val_loss: 0.4978 - val_accuracy: 0.8306\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5305 - accuracy: 0.8198 - val_loss: 0.4890 - val_accuracy: 0.8327\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5203 - accuracy: 0.8243 - val_loss: 0.4825 - val_accuracy: 0.8342\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5131 - accuracy: 0.8266 - val_loss: 0.4744 - val_accuracy: 0.8391\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5004 - accuracy: 0.8300 - val_loss: 0.4677 - val_accuracy: 0.8401\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4953 - accuracy: 0.8304 - val_loss: 0.4619 - val_accuracy: 0.8414\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.8331 - val_loss: 0.4576 - val_accuracy: 0.8394\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4808 - accuracy: 0.8354 - val_loss: 0.4516 - val_accuracy: 0.8428\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4772 - accuracy: 0.8366 - val_loss: 0.4474 - val_accuracy: 0.8446\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4706 - accuracy: 0.8386 - val_loss: 0.4429 - val_accuracy: 0.8461\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4679 - accuracy: 0.8395 - val_loss: 0.4402 - val_accuracy: 0.8468\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4614 - accuracy: 0.8410 - val_loss: 0.4357 - val_accuracy: 0.8487\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4578 - accuracy: 0.8419 - val_loss: 0.4324 - val_accuracy: 0.8484\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4526 - accuracy: 0.8443 - val_loss: 0.4281 - val_accuracy: 0.8503\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4479 - accuracy: 0.8455 - val_loss: 0.4270 - val_accuracy: 0.8507\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4431 - accuracy: 0.8471 - val_loss: 0.4215 - val_accuracy: 0.8528\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4398 - accuracy: 0.8484 - val_loss: 0.4199 - val_accuracy: 0.8546\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4386 - accuracy: 0.8464 - val_loss: 0.4169 - val_accuracy: 0.8542\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.8499 - val_loss: 0.4142 - val_accuracy: 0.8537\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4321 - accuracy: 0.8498 - val_loss: 0.4109 - val_accuracy: 0.8551\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4290 - accuracy: 0.8514 - val_loss: 0.4097 - val_accuracy: 0.8568\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4267 - accuracy: 0.8534 - val_loss: 0.4069 - val_accuracy: 0.8559\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8527 - val_loss: 0.4054 - val_accuracy: 0.8558\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4194 - accuracy: 0.8549 - val_loss: 0.4039 - val_accuracy: 0.8568\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4166 - accuracy: 0.8556 - val_loss: 0.4031 - val_accuracy: 0.8573\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4136 - accuracy: 0.8560 - val_loss: 0.3998 - val_accuracy: 0.8587\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4134 - accuracy: 0.8561 - val_loss: 0.3992 - val_accuracy: 0.8577\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4097 - accuracy: 0.8583 - val_loss: 0.3961 - val_accuracy: 0.8604\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4079 - accuracy: 0.8582 - val_loss: 0.3937 - val_accuracy: 0.8627\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4064 - accuracy: 0.8582 - val_loss: 0.3915 - val_accuracy: 0.8617\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4036 - accuracy: 0.8591 - val_loss: 0.3898 - val_accuracy: 0.8622\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4027 - accuracy: 0.8589 - val_loss: 0.3892 - val_accuracy: 0.8630\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8614 - val_loss: 0.3873 - val_accuracy: 0.8633\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3976 - accuracy: 0.8609 - val_loss: 0.3860 - val_accuracy: 0.8626\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3955 - accuracy: 0.8623 - val_loss: 0.3840 - val_accuracy: 0.8638\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3938 - accuracy: 0.8634 - val_loss: 0.3840 - val_accuracy: 0.8654\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3938 - accuracy: 0.8623 - val_loss: 0.3816 - val_accuracy: 0.8655\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3899 - accuracy: 0.8631 - val_loss: 0.3805 - val_accuracy: 0.8647\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3885 - accuracy: 0.8648 - val_loss: 0.3789 - val_accuracy: 0.8658\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.8644 - val_loss: 0.3785 - val_accuracy: 0.8662\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3875 - accuracy: 0.8647 - val_loss: 0.3767 - val_accuracy: 0.8668\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3855 - accuracy: 0.8651 - val_loss: 0.3751 - val_accuracy: 0.8667\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3829 - accuracy: 0.8663 - val_loss: 0.3748 - val_accuracy: 0.8679\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3818 - accuracy: 0.8665 - val_loss: 0.3737 - val_accuracy: 0.8670\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3803 - accuracy: 0.8665 - val_loss: 0.3734 - val_accuracy: 0.8680\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3785 - accuracy: 0.8669 - val_loss: 0.3715 - val_accuracy: 0.8675\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3782 - accuracy: 0.8672 - val_loss: 0.3698 - val_accuracy: 0.8689\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3755 - accuracy: 0.8690 - val_loss: 0.3690 - val_accuracy: 0.8692\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3757 - accuracy: 0.8675 - val_loss: 0.3689 - val_accuracy: 0.8685\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3747 - accuracy: 0.8688 - val_loss: 0.3678 - val_accuracy: 0.8698\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8702 - val_loss: 0.3667 - val_accuracy: 0.8702\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3695 - accuracy: 0.8705 - val_loss: 0.3660 - val_accuracy: 0.8702\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3726 - accuracy: 0.8689 - val_loss: 0.3664 - val_accuracy: 0.8691\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3675 - accuracy: 0.8723 - val_loss: 0.3654 - val_accuracy: 0.8694\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8708 - val_loss: 0.3642 - val_accuracy: 0.8701\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3649 - accuracy: 0.8719 - val_loss: 0.3631 - val_accuracy: 0.8702\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3644 - accuracy: 0.8723 - val_loss: 0.3615 - val_accuracy: 0.8727\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3640 - accuracy: 0.8734 - val_loss: 0.3609 - val_accuracy: 0.8714\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8728 - val_loss: 0.3600 - val_accuracy: 0.8728\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3623 - accuracy: 0.8721 - val_loss: 0.3600 - val_accuracy: 0.8723\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3603 - accuracy: 0.8747 - val_loss: 0.3591 - val_accuracy: 0.8723\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3595 - accuracy: 0.8740 - val_loss: 0.3585 - val_accuracy: 0.8730\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8740 - val_loss: 0.3573 - val_accuracy: 0.8724\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3583 - accuracy: 0.8742 - val_loss: 0.3560 - val_accuracy: 0.8729\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8740 - val_loss: 0.3569 - val_accuracy: 0.8726\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3551 - accuracy: 0.8748 - val_loss: 0.3554 - val_accuracy: 0.8727\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8758 - val_loss: 0.3563 - val_accuracy: 0.8723\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3537 - accuracy: 0.8764 - val_loss: 0.3529 - val_accuracy: 0.8750\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8763 - val_loss: 0.3544 - val_accuracy: 0.8734\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3510 - accuracy: 0.8772 - val_loss: 0.3527 - val_accuracy: 0.8750\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3520 - accuracy: 0.8761 - val_loss: 0.3513 - val_accuracy: 0.8741\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3505 - accuracy: 0.8764 - val_loss: 0.3506 - val_accuracy: 0.8744\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3487 - accuracy: 0.8769 - val_loss: 0.3505 - val_accuracy: 0.8740\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3479 - accuracy: 0.8784 - val_loss: 0.3490 - val_accuracy: 0.8758\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8787 - val_loss: 0.3478 - val_accuracy: 0.8767\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3463 - accuracy: 0.8775 - val_loss: 0.3491 - val_accuracy: 0.8748\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3461 - accuracy: 0.8777 - val_loss: 0.3480 - val_accuracy: 0.8760\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3458 - accuracy: 0.8780 - val_loss: 0.3469 - val_accuracy: 0.8763\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3443 - accuracy: 0.8789 - val_loss: 0.3471 - val_accuracy: 0.8758\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8790 - val_loss: 0.3477 - val_accuracy: 0.8742\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3421 - accuracy: 0.8789 - val_loss: 0.3473 - val_accuracy: 0.8771\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3411 - accuracy: 0.8799 - val_loss: 0.3454 - val_accuracy: 0.8759\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8812 - val_loss: 0.3447 - val_accuracy: 0.8775\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8803 - val_loss: 0.3440 - val_accuracy: 0.8772\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3377 - accuracy: 0.8820 - val_loss: 0.3432 - val_accuracy: 0.8773\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3378 - accuracy: 0.8802 - val_loss: 0.3426 - val_accuracy: 0.8772\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3369 - accuracy: 0.8810 - val_loss: 0.3448 - val_accuracy: 0.8758\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8833 - val_loss: 0.3419 - val_accuracy: 0.8787\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3358 - accuracy: 0.8828 - val_loss: 0.3420 - val_accuracy: 0.8773\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3359 - accuracy: 0.8831 - val_loss: 0.3411 - val_accuracy: 0.8780\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3349 - accuracy: 0.8825 - val_loss: 0.3414 - val_accuracy: 0.8788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jvpw11d-N6Ph",
        "outputId": "9effb084-76ea-40b1-b3c4-5ca5a1d5b263"
      },
      "source": [
        "# Checking model summary\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rArQAbw7JDyX",
        "outputId": "7fd7b76c-9c08-4404-eb29-1c9c2b8b0899"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model2.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3633 - accuracy: 0.8685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3633310794830322, 0.8684999942779541]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrvOe0r43xA7"
      },
      "source": [
        "Validation and testing accuracy is almost same as our previous MLP model. There is not much change in losses as well. One thing can be noticed, now our model has almost same training, validation and tetsing accuracy.\n",
        "Let's try to incraese the number of neurons to 256 and check if it improves the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koXYthpwwD3a"
      },
      "source": [
        "### 4. Building Multi-layer Perceptron with Dropout Normalization and increased neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxIM4Ws4JP3R",
        "outputId": "b93c912f-e570-477a-cfdb-8b0155744f9c"
      },
      "source": [
        "# Building Multi-layer Perceptron with Dropout Normalization and increased neurons\n",
        "tf.random.set_seed(42)\n",
        "model3= tf.keras.Sequential(name= 'mlp_3')\n",
        "model3.add(tf.keras.layers.Dense(256, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model3.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer1'))\n",
        "model3.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer2'))\n",
        "\n",
        "# Compiling the model\n",
        "model3.compile(optimizer= 'sgd', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history3= model3.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 1.2068 - accuracy: 0.6051 - val_loss: 0.8129 - val_accuracy: 0.7318\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7968 - accuracy: 0.7314 - val_loss: 0.6823 - val_accuracy: 0.7768\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.7011 - accuracy: 0.7654 - val_loss: 0.6204 - val_accuracy: 0.7954\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6469 - accuracy: 0.7840 - val_loss: 0.5821 - val_accuracy: 0.8067\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.6106 - accuracy: 0.7960 - val_loss: 0.5552 - val_accuracy: 0.8159\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5825 - accuracy: 0.8031 - val_loss: 0.5341 - val_accuracy: 0.8214\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5619 - accuracy: 0.8113 - val_loss: 0.5189 - val_accuracy: 0.8259\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5433 - accuracy: 0.8163 - val_loss: 0.5072 - val_accuracy: 0.8282\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5288 - accuracy: 0.8209 - val_loss: 0.4946 - val_accuracy: 0.8322\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.8232 - val_loss: 0.4863 - val_accuracy: 0.8323\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.5063 - accuracy: 0.8273 - val_loss: 0.4772 - val_accuracy: 0.8362\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4979 - accuracy: 0.8302 - val_loss: 0.4720 - val_accuracy: 0.8372\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4887 - accuracy: 0.8337 - val_loss: 0.4646 - val_accuracy: 0.8395\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4814 - accuracy: 0.8351 - val_loss: 0.4570 - val_accuracy: 0.8418\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4744 - accuracy: 0.8376 - val_loss: 0.4516 - val_accuracy: 0.8436\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4674 - accuracy: 0.8381 - val_loss: 0.4477 - val_accuracy: 0.8438\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4611 - accuracy: 0.8410 - val_loss: 0.4418 - val_accuracy: 0.8453\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4559 - accuracy: 0.8451 - val_loss: 0.4373 - val_accuracy: 0.8462\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8454 - val_loss: 0.4340 - val_accuracy: 0.8462\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4461 - accuracy: 0.8459 - val_loss: 0.4311 - val_accuracy: 0.8503\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4420 - accuracy: 0.8462 - val_loss: 0.4265 - val_accuracy: 0.8503\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4379 - accuracy: 0.8485 - val_loss: 0.4229 - val_accuracy: 0.8499\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.8492 - val_loss: 0.4207 - val_accuracy: 0.8521\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4300 - accuracy: 0.8515 - val_loss: 0.4184 - val_accuracy: 0.8546\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4249 - accuracy: 0.8514 - val_loss: 0.4131 - val_accuracy: 0.8540\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4227 - accuracy: 0.8527 - val_loss: 0.4123 - val_accuracy: 0.8551\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4193 - accuracy: 0.8535 - val_loss: 0.4083 - val_accuracy: 0.8580\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4159 - accuracy: 0.8541 - val_loss: 0.4061 - val_accuracy: 0.8555\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4115 - accuracy: 0.8559 - val_loss: 0.4036 - val_accuracy: 0.8572\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4104 - accuracy: 0.8560 - val_loss: 0.4021 - val_accuracy: 0.8571\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8590 - val_loss: 0.3997 - val_accuracy: 0.8587\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8598 - val_loss: 0.3974 - val_accuracy: 0.8598\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4020 - accuracy: 0.8604 - val_loss: 0.3959 - val_accuracy: 0.8608\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3980 - accuracy: 0.8598 - val_loss: 0.3953 - val_accuracy: 0.8597\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8625 - val_loss: 0.3922 - val_accuracy: 0.8609\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3948 - accuracy: 0.8621 - val_loss: 0.3915 - val_accuracy: 0.8611\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3929 - accuracy: 0.8606 - val_loss: 0.3889 - val_accuracy: 0.8622\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3907 - accuracy: 0.8634 - val_loss: 0.3869 - val_accuracy: 0.8633\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3869 - accuracy: 0.8645 - val_loss: 0.3842 - val_accuracy: 0.8648\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3856 - accuracy: 0.8646 - val_loss: 0.3826 - val_accuracy: 0.8650\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3825 - accuracy: 0.8656 - val_loss: 0.3829 - val_accuracy: 0.8643\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3816 - accuracy: 0.8659 - val_loss: 0.3810 - val_accuracy: 0.8645\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.8658 - val_loss: 0.3790 - val_accuracy: 0.8662\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3773 - accuracy: 0.8682 - val_loss: 0.3772 - val_accuracy: 0.8655\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3752 - accuracy: 0.8689 - val_loss: 0.3770 - val_accuracy: 0.8661\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3745 - accuracy: 0.8679 - val_loss: 0.3748 - val_accuracy: 0.8678\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3711 - accuracy: 0.8704 - val_loss: 0.3730 - val_accuracy: 0.8674\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8705 - val_loss: 0.3711 - val_accuracy: 0.8687\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3696 - accuracy: 0.8687 - val_loss: 0.3706 - val_accuracy: 0.8695\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8700 - val_loss: 0.3686 - val_accuracy: 0.8708\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3658 - accuracy: 0.8715 - val_loss: 0.3675 - val_accuracy: 0.8698\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3633 - accuracy: 0.8737 - val_loss: 0.3672 - val_accuracy: 0.8708\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3619 - accuracy: 0.8723 - val_loss: 0.3660 - val_accuracy: 0.8700\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3616 - accuracy: 0.8727 - val_loss: 0.3661 - val_accuracy: 0.8682\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3589 - accuracy: 0.8735 - val_loss: 0.3637 - val_accuracy: 0.8704\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3586 - accuracy: 0.8744 - val_loss: 0.3624 - val_accuracy: 0.8705\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8750 - val_loss: 0.3617 - val_accuracy: 0.8710\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.8755 - val_loss: 0.3602 - val_accuracy: 0.8727\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8768 - val_loss: 0.3594 - val_accuracy: 0.8727\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3546 - accuracy: 0.8767 - val_loss: 0.3591 - val_accuracy: 0.8731\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.8772 - val_loss: 0.3578 - val_accuracy: 0.8732\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3511 - accuracy: 0.8771 - val_loss: 0.3584 - val_accuracy: 0.8713\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.8773 - val_loss: 0.3566 - val_accuracy: 0.8722\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3484 - accuracy: 0.8780 - val_loss: 0.3570 - val_accuracy: 0.8708\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3466 - accuracy: 0.8783 - val_loss: 0.3546 - val_accuracy: 0.8727\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8783 - val_loss: 0.3553 - val_accuracy: 0.8745\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8796 - val_loss: 0.3525 - val_accuracy: 0.8736\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3450 - accuracy: 0.8788 - val_loss: 0.3522 - val_accuracy: 0.8722\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8814 - val_loss: 0.3514 - val_accuracy: 0.8729\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3406 - accuracy: 0.8807 - val_loss: 0.3503 - val_accuracy: 0.8748\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3393 - accuracy: 0.8802 - val_loss: 0.3506 - val_accuracy: 0.8758\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3394 - accuracy: 0.8807 - val_loss: 0.3491 - val_accuracy: 0.8746\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3368 - accuracy: 0.8813 - val_loss: 0.3480 - val_accuracy: 0.8752\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3367 - accuracy: 0.8806 - val_loss: 0.3482 - val_accuracy: 0.8762\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3363 - accuracy: 0.8831 - val_loss: 0.3469 - val_accuracy: 0.8759\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8824 - val_loss: 0.3479 - val_accuracy: 0.8755\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8821 - val_loss: 0.3449 - val_accuracy: 0.8767\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3328 - accuracy: 0.8834 - val_loss: 0.3462 - val_accuracy: 0.8745\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8829 - val_loss: 0.3437 - val_accuracy: 0.8783\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3305 - accuracy: 0.8838 - val_loss: 0.3432 - val_accuracy: 0.8770\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3303 - accuracy: 0.8826 - val_loss: 0.3420 - val_accuracy: 0.8777\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8849 - val_loss: 0.3419 - val_accuracy: 0.8777\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8833 - val_loss: 0.3409 - val_accuracy: 0.8766\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8855 - val_loss: 0.3400 - val_accuracy: 0.8787\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3261 - accuracy: 0.8854 - val_loss: 0.3402 - val_accuracy: 0.8779\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8869 - val_loss: 0.3403 - val_accuracy: 0.8785\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8862 - val_loss: 0.3385 - val_accuracy: 0.8780\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3232 - accuracy: 0.8869 - val_loss: 0.3376 - val_accuracy: 0.8793\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3222 - accuracy: 0.8869 - val_loss: 0.3383 - val_accuracy: 0.8779\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8874 - val_loss: 0.3379 - val_accuracy: 0.8796\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.8876 - val_loss: 0.3368 - val_accuracy: 0.8796\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8884 - val_loss: 0.3357 - val_accuracy: 0.8802\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3184 - accuracy: 0.8881 - val_loss: 0.3353 - val_accuracy: 0.8800\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8884 - val_loss: 0.3350 - val_accuracy: 0.8783\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3164 - accuracy: 0.8878 - val_loss: 0.3339 - val_accuracy: 0.8808\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3143 - accuracy: 0.8894 - val_loss: 0.3343 - val_accuracy: 0.8805\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3140 - accuracy: 0.8883 - val_loss: 0.3330 - val_accuracy: 0.8811\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3127 - accuracy: 0.8891 - val_loss: 0.3326 - val_accuracy: 0.8808\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8903 - val_loss: 0.3329 - val_accuracy: 0.8816\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8897 - val_loss: 0.3322 - val_accuracy: 0.8813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUIuX-Kk5ZXS",
        "outputId": "65840fce-1701-4bd9-e674-cdd83561db11"
      },
      "source": [
        "# Checking model summary\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMjEbrwyJsEw",
        "outputId": "e035b239-4371-435d-fe5c-e0d68bdb2878"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model3.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3550010323524475, 0.8736000061035156]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_wUkEO56S8Y"
      },
      "source": [
        "After incraesing number of hidden units, losses have been decreased and training, validation and testing accuracy also increased. Next, I'll try with Adam and RMSprop optimizers to check if that improves the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXhoXcRgwO8i"
      },
      "source": [
        "### 5. Building MLP with adam optimizer with all previous configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0c6ZQQzKicH",
        "outputId": "2f43590a-0d3a-47ae-a6ce-d46f0d528657"
      },
      "source": [
        "# Building MLP with adam optimizer with all previous configurations\n",
        "tf.random.set_seed(42)\n",
        "model4= tf.keras.Sequential(name= 'mlp_4')\n",
        "model4.add(tf.keras.layers.Dense(256, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model4.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer1'))\n",
        "model4.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer2'))\n",
        "\n",
        "# Compiling the model\n",
        "model4.compile(optimizer= 'rmsprop', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history4= model4.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 3ms/step - loss: 0.6187 - accuracy: 0.7827 - val_loss: 0.4447 - val_accuracy: 0.8407\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4324 - accuracy: 0.8460 - val_loss: 0.4154 - val_accuracy: 0.8481\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3867 - accuracy: 0.8585 - val_loss: 0.3786 - val_accuracy: 0.8633\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3621 - accuracy: 0.8683 - val_loss: 0.3515 - val_accuracy: 0.8758\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3431 - accuracy: 0.8745 - val_loss: 0.3496 - val_accuracy: 0.8738\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8786 - val_loss: 0.3296 - val_accuracy: 0.8831\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3208 - accuracy: 0.8832 - val_loss: 0.3401 - val_accuracy: 0.8834\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3119 - accuracy: 0.8871 - val_loss: 0.3321 - val_accuracy: 0.8857\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8905 - val_loss: 0.3332 - val_accuracy: 0.8808\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.8931 - val_loss: 0.3220 - val_accuracy: 0.8876\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2874 - accuracy: 0.8950 - val_loss: 0.3349 - val_accuracy: 0.8862\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2836 - accuracy: 0.8971 - val_loss: 0.3291 - val_accuracy: 0.8883\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2735 - accuracy: 0.9000 - val_loss: 0.3353 - val_accuracy: 0.8893\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2704 - accuracy: 0.9018 - val_loss: 0.3382 - val_accuracy: 0.8857\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.9007 - val_loss: 0.3219 - val_accuracy: 0.8882\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2623 - accuracy: 0.9050 - val_loss: 0.3179 - val_accuracy: 0.8944\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2555 - accuracy: 0.9062 - val_loss: 0.3529 - val_accuracy: 0.8906\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2531 - accuracy: 0.9074 - val_loss: 0.3220 - val_accuracy: 0.8934\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2497 - accuracy: 0.9088 - val_loss: 0.3276 - val_accuracy: 0.8947\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2464 - accuracy: 0.9098 - val_loss: 0.3306 - val_accuracy: 0.8904\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2431 - accuracy: 0.9113 - val_loss: 0.3382 - val_accuracy: 0.8913\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2404 - accuracy: 0.9129 - val_loss: 0.3360 - val_accuracy: 0.8956\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2339 - accuracy: 0.9130 - val_loss: 0.3519 - val_accuracy: 0.8907\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2333 - accuracy: 0.9144 - val_loss: 0.3352 - val_accuracy: 0.8953\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2260 - accuracy: 0.9180 - val_loss: 0.3314 - val_accuracy: 0.8946\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2252 - accuracy: 0.9172 - val_loss: 0.3497 - val_accuracy: 0.8932\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2231 - accuracy: 0.9192 - val_loss: 0.3518 - val_accuracy: 0.8917\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9207 - val_loss: 0.3650 - val_accuracy: 0.8880\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2174 - accuracy: 0.9200 - val_loss: 0.3487 - val_accuracy: 0.8959\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2133 - accuracy: 0.9215 - val_loss: 0.3397 - val_accuracy: 0.8967\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2125 - accuracy: 0.9219 - val_loss: 0.3650 - val_accuracy: 0.8923\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2131 - accuracy: 0.9225 - val_loss: 0.3481 - val_accuracy: 0.8964\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2059 - accuracy: 0.9246 - val_loss: 0.3489 - val_accuracy: 0.8972\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2077 - accuracy: 0.9242 - val_loss: 0.3666 - val_accuracy: 0.8946\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2043 - accuracy: 0.9241 - val_loss: 0.3694 - val_accuracy: 0.8917\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2005 - accuracy: 0.9257 - val_loss: 0.3727 - val_accuracy: 0.8942\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1992 - accuracy: 0.9273 - val_loss: 0.3661 - val_accuracy: 0.8954\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1970 - accuracy: 0.9276 - val_loss: 0.3739 - val_accuracy: 0.8963\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1941 - accuracy: 0.9290 - val_loss: 0.3711 - val_accuracy: 0.8988\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1917 - accuracy: 0.9298 - val_loss: 0.3618 - val_accuracy: 0.8969\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1898 - accuracy: 0.9311 - val_loss: 0.3793 - val_accuracy: 0.8931\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1876 - accuracy: 0.9313 - val_loss: 0.3693 - val_accuracy: 0.8986\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1881 - accuracy: 0.9323 - val_loss: 0.4039 - val_accuracy: 0.8917\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1891 - accuracy: 0.9306 - val_loss: 0.3871 - val_accuracy: 0.8947\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1853 - accuracy: 0.9326 - val_loss: 0.3816 - val_accuracy: 0.8931\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1867 - accuracy: 0.9330 - val_loss: 0.4191 - val_accuracy: 0.8923\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1825 - accuracy: 0.9334 - val_loss: 0.3989 - val_accuracy: 0.8920\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1789 - accuracy: 0.9354 - val_loss: 0.4026 - val_accuracy: 0.8972\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1779 - accuracy: 0.9358 - val_loss: 0.4028 - val_accuracy: 0.8961\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1768 - accuracy: 0.9356 - val_loss: 0.4200 - val_accuracy: 0.8946\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9372 - val_loss: 0.4073 - val_accuracy: 0.8967\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1763 - accuracy: 0.9360 - val_loss: 0.4091 - val_accuracy: 0.8938\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9367 - val_loss: 0.4197 - val_accuracy: 0.8955\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.9374 - val_loss: 0.4595 - val_accuracy: 0.8827\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9384 - val_loss: 0.4282 - val_accuracy: 0.8975\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9405 - val_loss: 0.4384 - val_accuracy: 0.8958\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1701 - accuracy: 0.9400 - val_loss: 0.4590 - val_accuracy: 0.8961\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9404 - val_loss: 0.4570 - val_accuracy: 0.8952\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9417 - val_loss: 0.4225 - val_accuracy: 0.8993\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9406 - val_loss: 0.4628 - val_accuracy: 0.8960\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9417 - val_loss: 0.4225 - val_accuracy: 0.8992\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1640 - accuracy: 0.9408 - val_loss: 0.4484 - val_accuracy: 0.8966\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9402 - val_loss: 0.4670 - val_accuracy: 0.8942\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9412 - val_loss: 0.4356 - val_accuracy: 0.8966\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9436 - val_loss: 0.4566 - val_accuracy: 0.8967\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9445 - val_loss: 0.4441 - val_accuracy: 0.8977\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9427 - val_loss: 0.4724 - val_accuracy: 0.8963\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9433 - val_loss: 0.4788 - val_accuracy: 0.8972\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1544 - accuracy: 0.9451 - val_loss: 0.4900 - val_accuracy: 0.8968\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9455 - val_loss: 0.4623 - val_accuracy: 0.8959\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1514 - accuracy: 0.9463 - val_loss: 0.4840 - val_accuracy: 0.8940\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1502 - accuracy: 0.9457 - val_loss: 0.4960 - val_accuracy: 0.8959\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1524 - accuracy: 0.9465 - val_loss: 0.5222 - val_accuracy: 0.8954\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9469 - val_loss: 0.4721 - val_accuracy: 0.8962\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1533 - accuracy: 0.9458 - val_loss: 0.4651 - val_accuracy: 0.8973\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1449 - accuracy: 0.9475 - val_loss: 0.4828 - val_accuracy: 0.8955\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1452 - accuracy: 0.9498 - val_loss: 0.5006 - val_accuracy: 0.8964\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9478 - val_loss: 0.5079 - val_accuracy: 0.8935\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1438 - accuracy: 0.9486 - val_loss: 0.5015 - val_accuracy: 0.8955\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1430 - accuracy: 0.9482 - val_loss: 0.4857 - val_accuracy: 0.8974\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1392 - accuracy: 0.9503 - val_loss: 0.5209 - val_accuracy: 0.8935\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1414 - accuracy: 0.9488 - val_loss: 0.5133 - val_accuracy: 0.8972\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.9502 - val_loss: 0.5125 - val_accuracy: 0.8978\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9495 - val_loss: 0.5051 - val_accuracy: 0.8959\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1409 - accuracy: 0.9504 - val_loss: 0.5475 - val_accuracy: 0.8904\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9500 - val_loss: 0.5205 - val_accuracy: 0.8966\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9513 - val_loss: 0.5390 - val_accuracy: 0.8982\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1394 - accuracy: 0.9517 - val_loss: 0.5160 - val_accuracy: 0.8989\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1399 - accuracy: 0.9501 - val_loss: 0.5677 - val_accuracy: 0.8947\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1355 - accuracy: 0.9524 - val_loss: 0.5771 - val_accuracy: 0.8937\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1389 - accuracy: 0.9519 - val_loss: 0.5292 - val_accuracy: 0.8952\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9508 - val_loss: 0.5360 - val_accuracy: 0.8947\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1379 - accuracy: 0.9516 - val_loss: 0.5577 - val_accuracy: 0.8942\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1342 - accuracy: 0.9539 - val_loss: 0.5578 - val_accuracy: 0.8983\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9526 - val_loss: 0.5690 - val_accuracy: 0.8946\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9531 - val_loss: 0.5553 - val_accuracy: 0.8949\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1304 - accuracy: 0.9527 - val_loss: 0.5383 - val_accuracy: 0.8969\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1299 - accuracy: 0.9543 - val_loss: 0.5968 - val_accuracy: 0.8948\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9551 - val_loss: 0.6030 - val_accuracy: 0.8938\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9539 - val_loss: 0.5705 - val_accuracy: 0.8955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-rMPRLe5Zrc",
        "outputId": "e216abd2-1e1e-469c-86c0-36780a0877c4"
      },
      "source": [
        "# Checking model summary\n",
        "model4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"mlp_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HUtqN6w72EN",
        "outputId": "467c27ec-2a30-47cb-c183-828343ff8cfe"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model4.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.6423 - accuracy: 0.8899\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6423174142837524, 0.8899000287055969]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLNslqox83Wc"
      },
      "source": [
        "After using RMSprop as optimizer, accuracy improved a in trainng, validation and as well as in testing. But difference between training and testing loss has been increased. Looks like model is started to overfit. Let's check with Adam optimizer, then we'll again address the issue of overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxNBZZwqwV9Z"
      },
      "source": [
        "### 6. Building MLP with adam optimizer with all previous configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNad6XGSLCcT",
        "outputId": "cd5d9bfc-277d-4eb8-b606-47218e7ffccd"
      },
      "source": [
        "# Building MLP with adam optimizer with all previous configurations\n",
        "tf.random.set_seed(42)\n",
        "model5= tf.keras.Sequential(name= 'mlp_5')\n",
        "model5.add(tf.keras.layers.Dense(256, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model5.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer1'))\n",
        "model5.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer2'))\n",
        "\n",
        "# Compiling the model\n",
        "model5.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history5= model5.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.6030 - accuracy: 0.7897 - val_loss: 0.4494 - val_accuracy: 0.8397\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4276 - accuracy: 0.8490 - val_loss: 0.3892 - val_accuracy: 0.8578\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3859 - accuracy: 0.8606 - val_loss: 0.3686 - val_accuracy: 0.8658\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3599 - accuracy: 0.8707 - val_loss: 0.3582 - val_accuracy: 0.8701\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3455 - accuracy: 0.8744 - val_loss: 0.3455 - val_accuracy: 0.8774\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8795 - val_loss: 0.3257 - val_accuracy: 0.8842\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.8828 - val_loss: 0.3202 - val_accuracy: 0.8863\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.8873 - val_loss: 0.3290 - val_accuracy: 0.8828\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2987 - accuracy: 0.8905 - val_loss: 0.3154 - val_accuracy: 0.8864\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2911 - accuracy: 0.8934 - val_loss: 0.3177 - val_accuracy: 0.8864\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2842 - accuracy: 0.8947 - val_loss: 0.3096 - val_accuracy: 0.8892\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2762 - accuracy: 0.8979 - val_loss: 0.3055 - val_accuracy: 0.8897\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2683 - accuracy: 0.9014 - val_loss: 0.3119 - val_accuracy: 0.8868\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2640 - accuracy: 0.9026 - val_loss: 0.3066 - val_accuracy: 0.8902\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.9042 - val_loss: 0.3028 - val_accuracy: 0.8912\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2538 - accuracy: 0.9058 - val_loss: 0.3002 - val_accuracy: 0.8908\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2485 - accuracy: 0.9077 - val_loss: 0.3063 - val_accuracy: 0.8903\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.9097 - val_loss: 0.3006 - val_accuracy: 0.8938\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.9105 - val_loss: 0.3062 - val_accuracy: 0.8901\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2360 - accuracy: 0.9104 - val_loss: 0.3014 - val_accuracy: 0.8932\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2336 - accuracy: 0.9122 - val_loss: 0.2962 - val_accuracy: 0.8934\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2286 - accuracy: 0.9136 - val_loss: 0.3027 - val_accuracy: 0.8953\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2210 - accuracy: 0.9163 - val_loss: 0.3081 - val_accuracy: 0.8928\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2195 - accuracy: 0.9186 - val_loss: 0.2971 - val_accuracy: 0.8953\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9182 - val_loss: 0.2996 - val_accuracy: 0.8955\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2119 - accuracy: 0.9202 - val_loss: 0.3112 - val_accuracy: 0.8951\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2105 - accuracy: 0.9200 - val_loss: 0.2988 - val_accuracy: 0.8976\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2054 - accuracy: 0.9218 - val_loss: 0.3099 - val_accuracy: 0.8904\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2036 - accuracy: 0.9228 - val_loss: 0.3051 - val_accuracy: 0.8967\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2031 - accuracy: 0.9242 - val_loss: 0.3087 - val_accuracy: 0.8927\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2001 - accuracy: 0.9244 - val_loss: 0.3058 - val_accuracy: 0.8967\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1927 - accuracy: 0.9279 - val_loss: 0.3060 - val_accuracy: 0.8955\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1975 - accuracy: 0.9248 - val_loss: 0.3032 - val_accuracy: 0.8984\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1911 - accuracy: 0.9284 - val_loss: 0.3109 - val_accuracy: 0.8968\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9279 - val_loss: 0.3081 - val_accuracy: 0.8967\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1879 - accuracy: 0.9281 - val_loss: 0.3135 - val_accuracy: 0.8954\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1826 - accuracy: 0.9306 - val_loss: 0.3158 - val_accuracy: 0.8944\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1813 - accuracy: 0.9310 - val_loss: 0.3113 - val_accuracy: 0.8972\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9340 - val_loss: 0.3130 - val_accuracy: 0.8973\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9331 - val_loss: 0.3128 - val_accuracy: 0.8959\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9348 - val_loss: 0.3100 - val_accuracy: 0.8970\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9346 - val_loss: 0.3069 - val_accuracy: 0.8992\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1686 - accuracy: 0.9370 - val_loss: 0.3146 - val_accuracy: 0.8979\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.9366 - val_loss: 0.3217 - val_accuracy: 0.8973\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1680 - accuracy: 0.9356 - val_loss: 0.3201 - val_accuracy: 0.8970\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9379 - val_loss: 0.3271 - val_accuracy: 0.9003\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1633 - accuracy: 0.9388 - val_loss: 0.3240 - val_accuracy: 0.8948\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9391 - val_loss: 0.3219 - val_accuracy: 0.8950\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1580 - accuracy: 0.9408 - val_loss: 0.3266 - val_accuracy: 0.8988\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9391 - val_loss: 0.3275 - val_accuracy: 0.8997\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1556 - accuracy: 0.9413 - val_loss: 0.3307 - val_accuracy: 0.8978\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1530 - accuracy: 0.9418 - val_loss: 0.3254 - val_accuracy: 0.8975\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1554 - accuracy: 0.9412 - val_loss: 0.3323 - val_accuracy: 0.9012\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1480 - accuracy: 0.9437 - val_loss: 0.3389 - val_accuracy: 0.8959\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1548 - accuracy: 0.9410 - val_loss: 0.3323 - val_accuracy: 0.9003\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1477 - accuracy: 0.9434 - val_loss: 0.3425 - val_accuracy: 0.9015\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1457 - accuracy: 0.9438 - val_loss: 0.3398 - val_accuracy: 0.9009\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1419 - accuracy: 0.9462 - val_loss: 0.3405 - val_accuracy: 0.9011\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1437 - accuracy: 0.9456 - val_loss: 0.3467 - val_accuracy: 0.8980\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1421 - accuracy: 0.9453 - val_loss: 0.3502 - val_accuracy: 0.8978\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1443 - accuracy: 0.9449 - val_loss: 0.3396 - val_accuracy: 0.8988\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1416 - accuracy: 0.9452 - val_loss: 0.3399 - val_accuracy: 0.8992\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9469 - val_loss: 0.3484 - val_accuracy: 0.8993\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1373 - accuracy: 0.9472 - val_loss: 0.3446 - val_accuracy: 0.8986\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9478 - val_loss: 0.3474 - val_accuracy: 0.8992\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9497 - val_loss: 0.3567 - val_accuracy: 0.8982\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1326 - accuracy: 0.9487 - val_loss: 0.3600 - val_accuracy: 0.8984\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1293 - accuracy: 0.9506 - val_loss: 0.3521 - val_accuracy: 0.9018\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1311 - accuracy: 0.9490 - val_loss: 0.3665 - val_accuracy: 0.8979\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9505 - val_loss: 0.3502 - val_accuracy: 0.8998\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1274 - accuracy: 0.9509 - val_loss: 0.3558 - val_accuracy: 0.8995\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1280 - accuracy: 0.9507 - val_loss: 0.3642 - val_accuracy: 0.8998\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1274 - accuracy: 0.9513 - val_loss: 0.3697 - val_accuracy: 0.9011\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9515 - val_loss: 0.3619 - val_accuracy: 0.8972\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9517 - val_loss: 0.3860 - val_accuracy: 0.8942\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9522 - val_loss: 0.3773 - val_accuracy: 0.8999\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1238 - accuracy: 0.9537 - val_loss: 0.3792 - val_accuracy: 0.8998\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1236 - accuracy: 0.9530 - val_loss: 0.3648 - val_accuracy: 0.8993\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1239 - accuracy: 0.9535 - val_loss: 0.3826 - val_accuracy: 0.8982\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1220 - accuracy: 0.9531 - val_loss: 0.3797 - val_accuracy: 0.9010\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1209 - accuracy: 0.9531 - val_loss: 0.3786 - val_accuracy: 0.8969\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 0.3792 - val_accuracy: 0.8991\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1155 - accuracy: 0.9558 - val_loss: 0.3683 - val_accuracy: 0.8975\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1160 - accuracy: 0.9555 - val_loss: 0.3877 - val_accuracy: 0.8997\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1159 - accuracy: 0.9550 - val_loss: 0.3974 - val_accuracy: 0.8986\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1184 - accuracy: 0.9554 - val_loss: 0.3898 - val_accuracy: 0.8965\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1180 - accuracy: 0.9548 - val_loss: 0.3858 - val_accuracy: 0.8988\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.3900 - val_accuracy: 0.8982\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1160 - accuracy: 0.9544 - val_loss: 0.4025 - val_accuracy: 0.8986\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1117 - accuracy: 0.9571 - val_loss: 0.4139 - val_accuracy: 0.8957\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9569 - val_loss: 0.3948 - val_accuracy: 0.9011\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1079 - accuracy: 0.9593 - val_loss: 0.4133 - val_accuracy: 0.9003\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1088 - accuracy: 0.9580 - val_loss: 0.3905 - val_accuracy: 0.9018\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1060 - accuracy: 0.9587 - val_loss: 0.3981 - val_accuracy: 0.8980\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1094 - accuracy: 0.9575 - val_loss: 0.4052 - val_accuracy: 0.8994\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1064 - accuracy: 0.9594 - val_loss: 0.4074 - val_accuracy: 0.8998\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1048 - accuracy: 0.9597 - val_loss: 0.3934 - val_accuracy: 0.9009\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1058 - accuracy: 0.9601 - val_loss: 0.4038 - val_accuracy: 0.9018\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1054 - accuracy: 0.9592 - val_loss: 0.3937 - val_accuracy: 0.9006\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9622 - val_loss: 0.4175 - val_accuracy: 0.8997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONVqUFht72I9",
        "outputId": "46d53254-7379-41ef-b4ad-2d1a5f8244b1"
      },
      "source": [
        "# Checking model summary\n",
        "model5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 203,530\n",
            "Trainable params: 203,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-1PPMIb72Q3",
        "outputId": "aad09cc4-431e-4634-9130-d6cdb770a0f9"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model5.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.8977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45901381969451904, 0.8977000117301941]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i659uYgN72b4"
      },
      "source": [
        "With Adam optimizer model performance is slightly better than our previous model. ur testing accuracy is better and loss in testing dataset is smaller than our last model. But still there is some difference in training and testing accuracy, and testing loss is bit higher than training loss. I'll use Adam optimizer and will add one more hidden layer with dropout normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bomvkk5wbBj"
      },
      "source": [
        "### 7. Building model with adam optimizer and 2 hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpFv8ZQ8NQ8S",
        "outputId": "d6d9aedd-29f6-4592-82cc-235d61ec3aa9"
      },
      "source": [
        "# Building model with adam optimizer and 2 hidden layers\n",
        "tf.random.set_seed(42)\n",
        "model6= tf.keras.Sequential(name= 'mlp_6')\n",
        "model6.add(tf.keras.layers.Dense(256, input_shape= (X_train_norm.shape[1],), activation= 'relu', name= 'dense_layer1'))\n",
        "model6.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer1'))\n",
        "model6.add(tf.keras.layers.Dense(256, activation= 'relu', name= 'dense_layer2'))\n",
        "model6.add(tf.keras.layers.Dropout(.3, name= 'dropout_layer2'))\n",
        "model6.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer3'))\n",
        "\n",
        "# Compiling the model\n",
        "model6.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history6= model6.fit(X_train_norm, y_train_cat, batch_size= 128, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "375/375 [==============================] - 2s 3ms/step - loss: 0.6209 - accuracy: 0.7771 - val_loss: 0.4291 - val_accuracy: 0.8461\n",
            "Epoch 2/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.8425 - val_loss: 0.3878 - val_accuracy: 0.8571\n",
            "Epoch 3/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3966 - accuracy: 0.8568 - val_loss: 0.3650 - val_accuracy: 0.8648\n",
            "Epoch 4/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3719 - accuracy: 0.8648 - val_loss: 0.3538 - val_accuracy: 0.8728\n",
            "Epoch 5/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3544 - accuracy: 0.8705 - val_loss: 0.3364 - val_accuracy: 0.8811\n",
            "Epoch 6/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3400 - accuracy: 0.8755 - val_loss: 0.3277 - val_accuracy: 0.8820\n",
            "Epoch 7/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3294 - accuracy: 0.8792 - val_loss: 0.3284 - val_accuracy: 0.8837\n",
            "Epoch 8/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8823 - val_loss: 0.3225 - val_accuracy: 0.8858\n",
            "Epoch 9/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3085 - accuracy: 0.8855 - val_loss: 0.3216 - val_accuracy: 0.8808\n",
            "Epoch 10/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.3037 - accuracy: 0.8878 - val_loss: 0.3181 - val_accuracy: 0.8848\n",
            "Epoch 11/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2940 - accuracy: 0.8906 - val_loss: 0.3089 - val_accuracy: 0.8896\n",
            "Epoch 12/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2902 - accuracy: 0.8903 - val_loss: 0.3106 - val_accuracy: 0.8908\n",
            "Epoch 13/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2821 - accuracy: 0.8939 - val_loss: 0.3250 - val_accuracy: 0.8813\n",
            "Epoch 14/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2824 - accuracy: 0.8947 - val_loss: 0.3118 - val_accuracy: 0.8871\n",
            "Epoch 15/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2761 - accuracy: 0.8956 - val_loss: 0.3021 - val_accuracy: 0.8888\n",
            "Epoch 16/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2680 - accuracy: 0.8995 - val_loss: 0.3043 - val_accuracy: 0.8919\n",
            "Epoch 17/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2654 - accuracy: 0.8999 - val_loss: 0.3097 - val_accuracy: 0.8872\n",
            "Epoch 18/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2606 - accuracy: 0.9013 - val_loss: 0.3022 - val_accuracy: 0.8937\n",
            "Epoch 19/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2596 - accuracy: 0.9025 - val_loss: 0.3092 - val_accuracy: 0.8903\n",
            "Epoch 20/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2527 - accuracy: 0.9042 - val_loss: 0.3057 - val_accuracy: 0.8936\n",
            "Epoch 21/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2478 - accuracy: 0.9066 - val_loss: 0.3042 - val_accuracy: 0.8935\n",
            "Epoch 22/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2435 - accuracy: 0.9081 - val_loss: 0.3036 - val_accuracy: 0.8932\n",
            "Epoch 23/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2441 - accuracy: 0.9077 - val_loss: 0.3067 - val_accuracy: 0.8901\n",
            "Epoch 24/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2402 - accuracy: 0.9099 - val_loss: 0.2985 - val_accuracy: 0.8938\n",
            "Epoch 25/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2373 - accuracy: 0.9091 - val_loss: 0.3039 - val_accuracy: 0.8934\n",
            "Epoch 26/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2364 - accuracy: 0.9114 - val_loss: 0.3065 - val_accuracy: 0.8950\n",
            "Epoch 27/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2335 - accuracy: 0.9120 - val_loss: 0.3119 - val_accuracy: 0.8953\n",
            "Epoch 28/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2289 - accuracy: 0.9134 - val_loss: 0.3066 - val_accuracy: 0.8957\n",
            "Epoch 29/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2258 - accuracy: 0.9146 - val_loss: 0.3041 - val_accuracy: 0.8933\n",
            "Epoch 30/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2222 - accuracy: 0.9153 - val_loss: 0.3050 - val_accuracy: 0.8964\n",
            "Epoch 31/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2207 - accuracy: 0.9162 - val_loss: 0.3012 - val_accuracy: 0.8982\n",
            "Epoch 32/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2156 - accuracy: 0.9185 - val_loss: 0.3097 - val_accuracy: 0.8972\n",
            "Epoch 33/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2183 - accuracy: 0.9180 - val_loss: 0.3044 - val_accuracy: 0.8985\n",
            "Epoch 34/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2121 - accuracy: 0.9196 - val_loss: 0.3065 - val_accuracy: 0.8968\n",
            "Epoch 35/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2127 - accuracy: 0.9180 - val_loss: 0.3069 - val_accuracy: 0.8941\n",
            "Epoch 36/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2107 - accuracy: 0.9200 - val_loss: 0.3092 - val_accuracy: 0.8937\n",
            "Epoch 37/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2077 - accuracy: 0.9200 - val_loss: 0.3077 - val_accuracy: 0.9004\n",
            "Epoch 38/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2043 - accuracy: 0.9218 - val_loss: 0.3104 - val_accuracy: 0.8967\n",
            "Epoch 39/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2046 - accuracy: 0.9219 - val_loss: 0.3129 - val_accuracy: 0.8949\n",
            "Epoch 40/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.2025 - accuracy: 0.9231 - val_loss: 0.3177 - val_accuracy: 0.8950\n",
            "Epoch 41/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1989 - accuracy: 0.9236 - val_loss: 0.3237 - val_accuracy: 0.8918\n",
            "Epoch 42/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1959 - accuracy: 0.9262 - val_loss: 0.3159 - val_accuracy: 0.8958\n",
            "Epoch 43/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1971 - accuracy: 0.9243 - val_loss: 0.3252 - val_accuracy: 0.8925\n",
            "Epoch 44/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1953 - accuracy: 0.9247 - val_loss: 0.3108 - val_accuracy: 0.8945\n",
            "Epoch 45/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1914 - accuracy: 0.9272 - val_loss: 0.3154 - val_accuracy: 0.8957\n",
            "Epoch 46/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1952 - accuracy: 0.9258 - val_loss: 0.3313 - val_accuracy: 0.8962\n",
            "Epoch 47/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1906 - accuracy: 0.9268 - val_loss: 0.3358 - val_accuracy: 0.8890\n",
            "Epoch 48/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1882 - accuracy: 0.9277 - val_loss: 0.3222 - val_accuracy: 0.8954\n",
            "Epoch 49/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1889 - accuracy: 0.9280 - val_loss: 0.3171 - val_accuracy: 0.8984\n",
            "Epoch 50/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9296 - val_loss: 0.3204 - val_accuracy: 0.9007\n",
            "Epoch 51/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1856 - accuracy: 0.9298 - val_loss: 0.3309 - val_accuracy: 0.8971\n",
            "Epoch 52/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1838 - accuracy: 0.9288 - val_loss: 0.3232 - val_accuracy: 0.8975\n",
            "Epoch 53/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9318 - val_loss: 0.3259 - val_accuracy: 0.8983\n",
            "Epoch 54/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1805 - accuracy: 0.9305 - val_loss: 0.3311 - val_accuracy: 0.8964\n",
            "Epoch 55/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1754 - accuracy: 0.9334 - val_loss: 0.3307 - val_accuracy: 0.8992\n",
            "Epoch 56/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1784 - accuracy: 0.9315 - val_loss: 0.3308 - val_accuracy: 0.8967\n",
            "Epoch 57/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.9305 - val_loss: 0.3258 - val_accuracy: 0.8996\n",
            "Epoch 58/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1750 - accuracy: 0.9335 - val_loss: 0.3239 - val_accuracy: 0.8994\n",
            "Epoch 59/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1724 - accuracy: 0.9334 - val_loss: 0.3577 - val_accuracy: 0.8948\n",
            "Epoch 60/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9342 - val_loss: 0.3383 - val_accuracy: 0.8982\n",
            "Epoch 61/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9348 - val_loss: 0.3371 - val_accuracy: 0.8964\n",
            "Epoch 62/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1711 - accuracy: 0.9345 - val_loss: 0.3360 - val_accuracy: 0.8970\n",
            "Epoch 63/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1729 - accuracy: 0.9322 - val_loss: 0.3364 - val_accuracy: 0.8949\n",
            "Epoch 64/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1683 - accuracy: 0.9361 - val_loss: 0.3292 - val_accuracy: 0.8987\n",
            "Epoch 65/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9366 - val_loss: 0.3341 - val_accuracy: 0.8988\n",
            "Epoch 66/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1634 - accuracy: 0.9384 - val_loss: 0.3340 - val_accuracy: 0.8950\n",
            "Epoch 67/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9381 - val_loss: 0.3321 - val_accuracy: 0.9009\n",
            "Epoch 68/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9367 - val_loss: 0.3397 - val_accuracy: 0.8986\n",
            "Epoch 69/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9378 - val_loss: 0.3394 - val_accuracy: 0.8988\n",
            "Epoch 70/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9400 - val_loss: 0.3680 - val_accuracy: 0.8997\n",
            "Epoch 71/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9380 - val_loss: 0.3477 - val_accuracy: 0.8952\n",
            "Epoch 72/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9395 - val_loss: 0.3428 - val_accuracy: 0.8992\n",
            "Epoch 73/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9389 - val_loss: 0.3519 - val_accuracy: 0.8938\n",
            "Epoch 74/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9407 - val_loss: 0.3572 - val_accuracy: 0.8961\n",
            "Epoch 75/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9423 - val_loss: 0.3606 - val_accuracy: 0.8955\n",
            "Epoch 76/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1576 - accuracy: 0.9408 - val_loss: 0.3491 - val_accuracy: 0.8964\n",
            "Epoch 77/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1515 - accuracy: 0.9416 - val_loss: 0.3617 - val_accuracy: 0.8971\n",
            "Epoch 78/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1541 - accuracy: 0.9412 - val_loss: 0.3575 - val_accuracy: 0.8976\n",
            "Epoch 79/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9409 - val_loss: 0.3536 - val_accuracy: 0.8982\n",
            "Epoch 80/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9426 - val_loss: 0.3528 - val_accuracy: 0.8982\n",
            "Epoch 81/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1521 - accuracy: 0.9425 - val_loss: 0.3540 - val_accuracy: 0.8947\n",
            "Epoch 82/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1509 - accuracy: 0.9422 - val_loss: 0.3560 - val_accuracy: 0.8989\n",
            "Epoch 83/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9420 - val_loss: 0.3628 - val_accuracy: 0.8982\n",
            "Epoch 84/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1498 - accuracy: 0.9425 - val_loss: 0.3587 - val_accuracy: 0.9009\n",
            "Epoch 85/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1436 - accuracy: 0.9450 - val_loss: 0.3705 - val_accuracy: 0.8978\n",
            "Epoch 86/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1463 - accuracy: 0.9437 - val_loss: 0.3833 - val_accuracy: 0.8974\n",
            "Epoch 87/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1459 - accuracy: 0.9440 - val_loss: 0.3837 - val_accuracy: 0.8976\n",
            "Epoch 88/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1446 - accuracy: 0.9445 - val_loss: 0.3810 - val_accuracy: 0.8981\n",
            "Epoch 89/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1450 - accuracy: 0.9456 - val_loss: 0.3790 - val_accuracy: 0.8955\n",
            "Epoch 90/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1429 - accuracy: 0.9454 - val_loss: 0.3781 - val_accuracy: 0.8974\n",
            "Epoch 91/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1469 - accuracy: 0.9447 - val_loss: 0.3953 - val_accuracy: 0.8961\n",
            "Epoch 92/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1441 - accuracy: 0.9436 - val_loss: 0.3733 - val_accuracy: 0.8999\n",
            "Epoch 93/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1371 - accuracy: 0.9468 - val_loss: 0.3692 - val_accuracy: 0.8996\n",
            "Epoch 94/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1439 - accuracy: 0.9442 - val_loss: 0.3689 - val_accuracy: 0.8979\n",
            "Epoch 95/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9451 - val_loss: 0.3731 - val_accuracy: 0.8998\n",
            "Epoch 96/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1407 - accuracy: 0.9468 - val_loss: 0.3711 - val_accuracy: 0.8960\n",
            "Epoch 97/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9476 - val_loss: 0.3794 - val_accuracy: 0.8964\n",
            "Epoch 98/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1385 - accuracy: 0.9471 - val_loss: 0.3786 - val_accuracy: 0.8967\n",
            "Epoch 99/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9476 - val_loss: 0.3824 - val_accuracy: 0.8991\n",
            "Epoch 100/100\n",
            "375/375 [==============================] - 1s 3ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 0.4075 - val_accuracy: 0.8978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm-30Ofu4K1j",
        "outputId": "66828fc8-217b-4397-9b2f-8000e5ebea7e"
      },
      "source": [
        "# Checking model summary\n",
        "model6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_layer2 (Dropout)     (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer3 (Dense)         (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 269,322\n",
            "Trainable params: 269,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6F_1iAwNsi-",
        "outputId": "ce5a73b8-3ef1-4df9-ee2f-506a6472a296"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model6.evaluate(X_test_norm, y_test_cat, batch_size= 128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8944\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.42908379435539246, 0.8944000005722046]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFkhwqmbA2xv"
      },
      "source": [
        "Increasing hidden layers, reduced testing loss. Next, I'll try to reduce batchsize to check if it improves the performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCPkGL9SwhuE"
      },
      "source": [
        "### 8. Building model with increased neurons, dropout rate and he initialization for hidden layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uGNZEoAYUaL",
        "outputId": "5f56b581-cdbe-4569-dfb9-ac387f108dce"
      },
      "source": [
        "# Building model with increased neurons, dropout rate and he initialization for hidden layers\n",
        "tf.random.set_seed(42)\n",
        "model_7= tf.keras.Sequential(name= 'mlp7')\n",
        "model_7.add(tf.keras.layers.Dense(392, input_shape= (X_train_norm.shape[1],), kernel_initializer= 'he_normal', activation= 'relu', name= 'dense_layer1'))\n",
        "model_7.add(tf.keras.layers.Dropout(.5, name= 'dropout_layer1'))\n",
        "model_7.add(tf.keras.layers.Dense(196, kernel_initializer= 'he_normal', activation= 'relu', name= 'dense_layer2'))\n",
        "model_7.add(tf.keras.layers.Dropout(.5, name= 'dropout_layer2'))\n",
        "model_7.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer3'))\n",
        "\n",
        "# Compiling the model\n",
        "model_7.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model with lower batch_size\n",
        "history_7= model_7.fit(X_train_norm, y_train_cat, batch_size= 64, epochs= 100, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.7053 - accuracy: 0.7446 - val_loss: 0.4491 - val_accuracy: 0.8329\n",
            "Epoch 2/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.5061 - accuracy: 0.8179 - val_loss: 0.4173 - val_accuracy: 0.8454\n",
            "Epoch 3/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.8315 - val_loss: 0.3861 - val_accuracy: 0.8598\n",
            "Epoch 4/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4375 - accuracy: 0.8439 - val_loss: 0.3656 - val_accuracy: 0.8673\n",
            "Epoch 5/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4204 - accuracy: 0.8479 - val_loss: 0.3689 - val_accuracy: 0.8649\n",
            "Epoch 6/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4059 - accuracy: 0.8544 - val_loss: 0.3531 - val_accuracy: 0.8731\n",
            "Epoch 7/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3943 - accuracy: 0.8557 - val_loss: 0.3448 - val_accuracy: 0.8701\n",
            "Epoch 8/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3871 - accuracy: 0.8604 - val_loss: 0.3628 - val_accuracy: 0.8643\n",
            "Epoch 9/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3801 - accuracy: 0.8629 - val_loss: 0.3390 - val_accuracy: 0.8728\n",
            "Epoch 10/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3700 - accuracy: 0.8651 - val_loss: 0.3357 - val_accuracy: 0.8763\n",
            "Epoch 11/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3663 - accuracy: 0.8660 - val_loss: 0.3306 - val_accuracy: 0.8825\n",
            "Epoch 12/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3596 - accuracy: 0.8678 - val_loss: 0.3262 - val_accuracy: 0.8841\n",
            "Epoch 13/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3562 - accuracy: 0.8696 - val_loss: 0.3335 - val_accuracy: 0.8770\n",
            "Epoch 14/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.8701 - val_loss: 0.3389 - val_accuracy: 0.8686\n",
            "Epoch 15/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3436 - accuracy: 0.8750 - val_loss: 0.3237 - val_accuracy: 0.8773\n",
            "Epoch 16/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3361 - accuracy: 0.8769 - val_loss: 0.3204 - val_accuracy: 0.8833\n",
            "Epoch 17/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3365 - accuracy: 0.8757 - val_loss: 0.3267 - val_accuracy: 0.8773\n",
            "Epoch 18/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3316 - accuracy: 0.8773 - val_loss: 0.3251 - val_accuracy: 0.8818\n",
            "Epoch 19/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8795 - val_loss: 0.3155 - val_accuracy: 0.8827\n",
            "Epoch 20/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3235 - accuracy: 0.8806 - val_loss: 0.3190 - val_accuracy: 0.8852\n",
            "Epoch 21/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3266 - accuracy: 0.8806 - val_loss: 0.3163 - val_accuracy: 0.8816\n",
            "Epoch 22/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3177 - accuracy: 0.8842 - val_loss: 0.3146 - val_accuracy: 0.8880\n",
            "Epoch 23/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3185 - accuracy: 0.8814 - val_loss: 0.3151 - val_accuracy: 0.8837\n",
            "Epoch 24/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3160 - accuracy: 0.8833 - val_loss: 0.3125 - val_accuracy: 0.8871\n",
            "Epoch 25/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3152 - accuracy: 0.8830 - val_loss: 0.3125 - val_accuracy: 0.8870\n",
            "Epoch 26/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3122 - accuracy: 0.8864 - val_loss: 0.3103 - val_accuracy: 0.8854\n",
            "Epoch 27/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3127 - accuracy: 0.8851 - val_loss: 0.3127 - val_accuracy: 0.8898\n",
            "Epoch 28/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3028 - accuracy: 0.8880 - val_loss: 0.3116 - val_accuracy: 0.8860\n",
            "Epoch 29/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3048 - accuracy: 0.8872 - val_loss: 0.3145 - val_accuracy: 0.8848\n",
            "Epoch 30/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3013 - accuracy: 0.8880 - val_loss: 0.3141 - val_accuracy: 0.8851\n",
            "Epoch 31/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2967 - accuracy: 0.8889 - val_loss: 0.3090 - val_accuracy: 0.8899\n",
            "Epoch 32/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2996 - accuracy: 0.8903 - val_loss: 0.3094 - val_accuracy: 0.8890\n",
            "Epoch 33/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2953 - accuracy: 0.8912 - val_loss: 0.3168 - val_accuracy: 0.8862\n",
            "Epoch 34/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2945 - accuracy: 0.8931 - val_loss: 0.3127 - val_accuracy: 0.8883\n",
            "Epoch 35/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2910 - accuracy: 0.8913 - val_loss: 0.3108 - val_accuracy: 0.8873\n",
            "Epoch 36/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2914 - accuracy: 0.8917 - val_loss: 0.3210 - val_accuracy: 0.8813\n",
            "Epoch 37/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2867 - accuracy: 0.8930 - val_loss: 0.3137 - val_accuracy: 0.8898\n",
            "Epoch 38/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2887 - accuracy: 0.8933 - val_loss: 0.3090 - val_accuracy: 0.8918\n",
            "Epoch 39/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2844 - accuracy: 0.8941 - val_loss: 0.3089 - val_accuracy: 0.8906\n",
            "Epoch 40/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2878 - accuracy: 0.8951 - val_loss: 0.3018 - val_accuracy: 0.8919\n",
            "Epoch 41/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2810 - accuracy: 0.8959 - val_loss: 0.3071 - val_accuracy: 0.8914\n",
            "Epoch 42/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2832 - accuracy: 0.8957 - val_loss: 0.3111 - val_accuracy: 0.8907\n",
            "Epoch 43/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2839 - accuracy: 0.8957 - val_loss: 0.3143 - val_accuracy: 0.8881\n",
            "Epoch 44/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2797 - accuracy: 0.8962 - val_loss: 0.3045 - val_accuracy: 0.8929\n",
            "Epoch 45/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2733 - accuracy: 0.8983 - val_loss: 0.3134 - val_accuracy: 0.8898\n",
            "Epoch 46/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2755 - accuracy: 0.8965 - val_loss: 0.3249 - val_accuracy: 0.8857\n",
            "Epoch 47/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2749 - accuracy: 0.8985 - val_loss: 0.3157 - val_accuracy: 0.8901\n",
            "Epoch 48/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2737 - accuracy: 0.8991 - val_loss: 0.3137 - val_accuracy: 0.8925\n",
            "Epoch 49/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2714 - accuracy: 0.9004 - val_loss: 0.3061 - val_accuracy: 0.8892\n",
            "Epoch 50/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2708 - accuracy: 0.8980 - val_loss: 0.3157 - val_accuracy: 0.8937\n",
            "Epoch 51/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2699 - accuracy: 0.8998 - val_loss: 0.3040 - val_accuracy: 0.8926\n",
            "Epoch 52/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2687 - accuracy: 0.8995 - val_loss: 0.3068 - val_accuracy: 0.8939\n",
            "Epoch 53/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2648 - accuracy: 0.9018 - val_loss: 0.3030 - val_accuracy: 0.8937\n",
            "Epoch 54/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2648 - accuracy: 0.9021 - val_loss: 0.3167 - val_accuracy: 0.8893\n",
            "Epoch 55/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2661 - accuracy: 0.9014 - val_loss: 0.3131 - val_accuracy: 0.8923\n",
            "Epoch 56/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2684 - accuracy: 0.9009 - val_loss: 0.3244 - val_accuracy: 0.8873\n",
            "Epoch 57/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2636 - accuracy: 0.9011 - val_loss: 0.3117 - val_accuracy: 0.8953\n",
            "Epoch 58/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2627 - accuracy: 0.9021 - val_loss: 0.3201 - val_accuracy: 0.8947\n",
            "Epoch 59/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2588 - accuracy: 0.9049 - val_loss: 0.3145 - val_accuracy: 0.8929\n",
            "Epoch 60/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2624 - accuracy: 0.9036 - val_loss: 0.3133 - val_accuracy: 0.8942\n",
            "Epoch 61/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2637 - accuracy: 0.9021 - val_loss: 0.3166 - val_accuracy: 0.8928\n",
            "Epoch 62/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2607 - accuracy: 0.9009 - val_loss: 0.3140 - val_accuracy: 0.8903\n",
            "Epoch 63/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2541 - accuracy: 0.9051 - val_loss: 0.3144 - val_accuracy: 0.8901\n",
            "Epoch 64/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2524 - accuracy: 0.9059 - val_loss: 0.3164 - val_accuracy: 0.8927\n",
            "Epoch 65/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2557 - accuracy: 0.9052 - val_loss: 0.3181 - val_accuracy: 0.8933\n",
            "Epoch 66/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2519 - accuracy: 0.9074 - val_loss: 0.3238 - val_accuracy: 0.8907\n",
            "Epoch 67/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2546 - accuracy: 0.9048 - val_loss: 0.3121 - val_accuracy: 0.8944\n",
            "Epoch 68/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2556 - accuracy: 0.9044 - val_loss: 0.3133 - val_accuracy: 0.8941\n",
            "Epoch 69/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2526 - accuracy: 0.9061 - val_loss: 0.3152 - val_accuracy: 0.8952\n",
            "Epoch 70/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2488 - accuracy: 0.9069 - val_loss: 0.3144 - val_accuracy: 0.8911\n",
            "Epoch 71/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2508 - accuracy: 0.9079 - val_loss: 0.3184 - val_accuracy: 0.8906\n",
            "Epoch 72/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2504 - accuracy: 0.9075 - val_loss: 0.3190 - val_accuracy: 0.8898\n",
            "Epoch 73/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2494 - accuracy: 0.9074 - val_loss: 0.3146 - val_accuracy: 0.8918\n",
            "Epoch 74/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2447 - accuracy: 0.9085 - val_loss: 0.3223 - val_accuracy: 0.8918\n",
            "Epoch 75/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2437 - accuracy: 0.9100 - val_loss: 0.3185 - val_accuracy: 0.8938\n",
            "Epoch 76/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2467 - accuracy: 0.9091 - val_loss: 0.3228 - val_accuracy: 0.8941\n",
            "Epoch 77/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2449 - accuracy: 0.9089 - val_loss: 0.3267 - val_accuracy: 0.8899\n",
            "Epoch 78/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2470 - accuracy: 0.9085 - val_loss: 0.3345 - val_accuracy: 0.8917\n",
            "Epoch 79/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2444 - accuracy: 0.9090 - val_loss: 0.3206 - val_accuracy: 0.8946\n",
            "Epoch 80/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2418 - accuracy: 0.9092 - val_loss: 0.3307 - val_accuracy: 0.8941\n",
            "Epoch 81/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2414 - accuracy: 0.9109 - val_loss: 0.3239 - val_accuracy: 0.8934\n",
            "Epoch 82/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2398 - accuracy: 0.9113 - val_loss: 0.3212 - val_accuracy: 0.8958\n",
            "Epoch 83/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2377 - accuracy: 0.9111 - val_loss: 0.3265 - val_accuracy: 0.8953\n",
            "Epoch 84/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2418 - accuracy: 0.9099 - val_loss: 0.3317 - val_accuracy: 0.8938\n",
            "Epoch 85/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2425 - accuracy: 0.9103 - val_loss: 0.3219 - val_accuracy: 0.8935\n",
            "Epoch 86/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2383 - accuracy: 0.9111 - val_loss: 0.3249 - val_accuracy: 0.8939\n",
            "Epoch 87/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2394 - accuracy: 0.9112 - val_loss: 0.3324 - val_accuracy: 0.8930\n",
            "Epoch 88/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2421 - accuracy: 0.9114 - val_loss: 0.3249 - val_accuracy: 0.8952\n",
            "Epoch 89/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2365 - accuracy: 0.9141 - val_loss: 0.3277 - val_accuracy: 0.8923\n",
            "Epoch 90/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2338 - accuracy: 0.9129 - val_loss: 0.3281 - val_accuracy: 0.8927\n",
            "Epoch 91/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2387 - accuracy: 0.9114 - val_loss: 0.3344 - val_accuracy: 0.8937\n",
            "Epoch 92/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2397 - accuracy: 0.9118 - val_loss: 0.3232 - val_accuracy: 0.8940\n",
            "Epoch 93/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2264 - accuracy: 0.9161 - val_loss: 0.3187 - val_accuracy: 0.8977\n",
            "Epoch 94/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2341 - accuracy: 0.9145 - val_loss: 0.3199 - val_accuracy: 0.8950\n",
            "Epoch 95/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2316 - accuracy: 0.9148 - val_loss: 0.3275 - val_accuracy: 0.8954\n",
            "Epoch 96/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2274 - accuracy: 0.9148 - val_loss: 0.3317 - val_accuracy: 0.8944\n",
            "Epoch 97/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2326 - accuracy: 0.9139 - val_loss: 0.3250 - val_accuracy: 0.8976\n",
            "Epoch 98/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2295 - accuracy: 0.9153 - val_loss: 0.3320 - val_accuracy: 0.8974\n",
            "Epoch 99/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2309 - accuracy: 0.9150 - val_loss: 0.3394 - val_accuracy: 0.8940\n",
            "Epoch 100/100\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2241 - accuracy: 0.9168 - val_loss: 0.3414 - val_accuracy: 0.8951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdSGrrikbWHO",
        "outputId": "62b282d6-b421-4445-ae6b-b5e0a7e93dcc"
      },
      "source": [
        "# Checking model summary\n",
        "model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 392)               307720    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 392)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 196)               77028     \n",
            "_________________________________________________________________\n",
            "dropout_layer2 (Dropout)     (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer3 (Dense)         (None, 10)                1970      \n",
            "=================================================================\n",
            "Total params: 386,718\n",
            "Trainable params: 386,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdPglOgpbZ5A",
        "outputId": "c0b7ad6f-53fe-4aaf-cbcd-2273882ed529"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model_7.evaluate(X_test_norm, y_test_cat, batch_size= 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step - loss: 0.3709 - accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37090638279914856, 0.8899999856948853]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvdE8Ca7biT-"
      },
      "source": [
        "After changing number of hidden units and increasing rate of dropout, we have got training accuracy of 91% and tetsing accuracy of 89%. Difference between tarining and tetsing loss has also reduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT6njSyFwp7C"
      },
      "source": [
        "### 9. Building exact same model as previous and training the model for more epochs\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtAvRzdHBYne",
        "outputId": "e7022021-a87a-43d7-8e97-21216c97bb29"
      },
      "source": [
        "# Building exact same model as previous and training the model for more epochs\n",
        "tf.random.set_seed(42)\n",
        "model_8= tf.keras.Sequential(name= 'mlp8')\n",
        "model_8.add(tf.keras.layers.Dense(392, input_shape= (X_train_norm.shape[1],), activation= 'relu', kernel_initializer= 'he_normal', name= 'dense_layer1'))\n",
        "model_8.add(tf.keras.layers.Dropout(.5, name= 'dropout_layer1'))\n",
        "model_8.add(tf.keras.layers.Dense(196, activation= 'relu', kernel_initializer= 'he_normal', name= 'dense_layer2'))\n",
        "model_8.add(tf.keras.layers.Dropout(.5, name= 'dropout_layer2'))\n",
        "model_8.add(tf.keras.layers.Dense(10, activation= 'softmax', name= 'dense_layer3'))\n",
        "\n",
        "# Compiling the model\n",
        "model_8.compile(optimizer= 'adam', loss= 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "# Training the model with lower batch_size\n",
        "history_8= model_8.fit(X_train_norm, y_train_cat, batch_size= 64, epochs= 200, validation_split= .2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.7053 - accuracy: 0.7446 - val_loss: 0.4491 - val_accuracy: 0.8329\n",
            "Epoch 2/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.5058 - accuracy: 0.8171 - val_loss: 0.4124 - val_accuracy: 0.8476\n",
            "Epoch 3/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4642 - accuracy: 0.8310 - val_loss: 0.3859 - val_accuracy: 0.8571\n",
            "Epoch 4/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4367 - accuracy: 0.8424 - val_loss: 0.3686 - val_accuracy: 0.8700\n",
            "Epoch 5/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4208 - accuracy: 0.8475 - val_loss: 0.3711 - val_accuracy: 0.8673\n",
            "Epoch 6/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.4092 - accuracy: 0.8515 - val_loss: 0.3606 - val_accuracy: 0.8684\n",
            "Epoch 7/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3966 - accuracy: 0.8557 - val_loss: 0.3462 - val_accuracy: 0.8714\n",
            "Epoch 8/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3886 - accuracy: 0.8580 - val_loss: 0.3548 - val_accuracy: 0.8698\n",
            "Epoch 9/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3787 - accuracy: 0.8628 - val_loss: 0.3367 - val_accuracy: 0.8776\n",
            "Epoch 10/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3714 - accuracy: 0.8648 - val_loss: 0.3343 - val_accuracy: 0.8752\n",
            "Epoch 11/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3648 - accuracy: 0.8668 - val_loss: 0.3306 - val_accuracy: 0.8800\n",
            "Epoch 12/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3571 - accuracy: 0.8698 - val_loss: 0.3325 - val_accuracy: 0.8802\n",
            "Epoch 13/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3561 - accuracy: 0.8695 - val_loss: 0.3377 - val_accuracy: 0.8773\n",
            "Epoch 14/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3495 - accuracy: 0.8710 - val_loss: 0.3273 - val_accuracy: 0.8750\n",
            "Epoch 15/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3404 - accuracy: 0.8757 - val_loss: 0.3260 - val_accuracy: 0.8816\n",
            "Epoch 16/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3421 - accuracy: 0.8748 - val_loss: 0.3249 - val_accuracy: 0.8823\n",
            "Epoch 17/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3394 - accuracy: 0.8753 - val_loss: 0.3284 - val_accuracy: 0.8838\n",
            "Epoch 18/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3287 - accuracy: 0.8777 - val_loss: 0.3249 - val_accuracy: 0.8813\n",
            "Epoch 19/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3272 - accuracy: 0.8795 - val_loss: 0.3309 - val_accuracy: 0.8790\n",
            "Epoch 20/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3267 - accuracy: 0.8792 - val_loss: 0.3239 - val_accuracy: 0.8829\n",
            "Epoch 21/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3245 - accuracy: 0.8787 - val_loss: 0.3134 - val_accuracy: 0.8858\n",
            "Epoch 22/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3219 - accuracy: 0.8834 - val_loss: 0.3196 - val_accuracy: 0.8867\n",
            "Epoch 23/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3184 - accuracy: 0.8811 - val_loss: 0.3179 - val_accuracy: 0.8857\n",
            "Epoch 24/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3163 - accuracy: 0.8835 - val_loss: 0.3096 - val_accuracy: 0.8883\n",
            "Epoch 25/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3141 - accuracy: 0.8836 - val_loss: 0.3053 - val_accuracy: 0.8881\n",
            "Epoch 26/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3115 - accuracy: 0.8844 - val_loss: 0.3123 - val_accuracy: 0.8877\n",
            "Epoch 27/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3113 - accuracy: 0.8844 - val_loss: 0.3077 - val_accuracy: 0.8917\n",
            "Epoch 28/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3032 - accuracy: 0.8877 - val_loss: 0.3141 - val_accuracy: 0.8864\n",
            "Epoch 29/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3023 - accuracy: 0.8868 - val_loss: 0.3057 - val_accuracy: 0.8859\n",
            "Epoch 30/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2980 - accuracy: 0.8896 - val_loss: 0.3095 - val_accuracy: 0.8891\n",
            "Epoch 31/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3020 - accuracy: 0.8888 - val_loss: 0.3130 - val_accuracy: 0.8866\n",
            "Epoch 32/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2984 - accuracy: 0.8901 - val_loss: 0.3039 - val_accuracy: 0.8947\n",
            "Epoch 33/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2949 - accuracy: 0.8921 - val_loss: 0.3095 - val_accuracy: 0.8839\n",
            "Epoch 34/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2941 - accuracy: 0.8932 - val_loss: 0.3026 - val_accuracy: 0.8919\n",
            "Epoch 35/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2908 - accuracy: 0.8913 - val_loss: 0.3171 - val_accuracy: 0.8847\n",
            "Epoch 36/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2967 - accuracy: 0.8905 - val_loss: 0.3022 - val_accuracy: 0.8903\n",
            "Epoch 37/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2878 - accuracy: 0.8926 - val_loss: 0.3081 - val_accuracy: 0.8917\n",
            "Epoch 38/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2891 - accuracy: 0.8936 - val_loss: 0.3041 - val_accuracy: 0.8924\n",
            "Epoch 39/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2826 - accuracy: 0.8961 - val_loss: 0.3059 - val_accuracy: 0.8926\n",
            "Epoch 40/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2909 - accuracy: 0.8924 - val_loss: 0.3106 - val_accuracy: 0.8904\n",
            "Epoch 41/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2858 - accuracy: 0.8946 - val_loss: 0.3006 - val_accuracy: 0.8909\n",
            "Epoch 42/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2829 - accuracy: 0.8962 - val_loss: 0.3076 - val_accuracy: 0.8924\n",
            "Epoch 43/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2863 - accuracy: 0.8942 - val_loss: 0.3159 - val_accuracy: 0.8888\n",
            "Epoch 44/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2788 - accuracy: 0.8971 - val_loss: 0.3102 - val_accuracy: 0.8923\n",
            "Epoch 45/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2797 - accuracy: 0.8957 - val_loss: 0.3194 - val_accuracy: 0.8883\n",
            "Epoch 46/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2763 - accuracy: 0.8968 - val_loss: 0.3130 - val_accuracy: 0.8884\n",
            "Epoch 47/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2811 - accuracy: 0.8963 - val_loss: 0.3157 - val_accuracy: 0.8907\n",
            "Epoch 48/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2714 - accuracy: 0.9000 - val_loss: 0.3225 - val_accuracy: 0.8913\n",
            "Epoch 49/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2728 - accuracy: 0.8997 - val_loss: 0.3180 - val_accuracy: 0.8894\n",
            "Epoch 50/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2733 - accuracy: 0.8989 - val_loss: 0.3054 - val_accuracy: 0.8946\n",
            "Epoch 51/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2650 - accuracy: 0.9018 - val_loss: 0.3059 - val_accuracy: 0.8911\n",
            "Epoch 52/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2692 - accuracy: 0.9001 - val_loss: 0.3082 - val_accuracy: 0.8932\n",
            "Epoch 53/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2688 - accuracy: 0.9004 - val_loss: 0.3049 - val_accuracy: 0.8946\n",
            "Epoch 54/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2673 - accuracy: 0.8998 - val_loss: 0.3131 - val_accuracy: 0.8878\n",
            "Epoch 55/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2700 - accuracy: 0.8997 - val_loss: 0.3015 - val_accuracy: 0.8942\n",
            "Epoch 56/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2630 - accuracy: 0.9030 - val_loss: 0.3205 - val_accuracy: 0.8923\n",
            "Epoch 57/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2637 - accuracy: 0.9006 - val_loss: 0.3075 - val_accuracy: 0.8949\n",
            "Epoch 58/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2654 - accuracy: 0.9016 - val_loss: 0.3082 - val_accuracy: 0.8947\n",
            "Epoch 59/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2581 - accuracy: 0.9046 - val_loss: 0.3146 - val_accuracy: 0.8917\n",
            "Epoch 60/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2604 - accuracy: 0.9021 - val_loss: 0.3098 - val_accuracy: 0.8939\n",
            "Epoch 61/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2574 - accuracy: 0.9046 - val_loss: 0.3109 - val_accuracy: 0.8955\n",
            "Epoch 62/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2591 - accuracy: 0.9047 - val_loss: 0.3183 - val_accuracy: 0.8921\n",
            "Epoch 63/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2582 - accuracy: 0.9048 - val_loss: 0.3169 - val_accuracy: 0.8916\n",
            "Epoch 64/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2542 - accuracy: 0.9055 - val_loss: 0.3047 - val_accuracy: 0.8956\n",
            "Epoch 65/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2562 - accuracy: 0.9051 - val_loss: 0.3157 - val_accuracy: 0.8937\n",
            "Epoch 66/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2559 - accuracy: 0.9049 - val_loss: 0.3163 - val_accuracy: 0.8917\n",
            "Epoch 67/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2555 - accuracy: 0.9053 - val_loss: 0.3190 - val_accuracy: 0.8909\n",
            "Epoch 68/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2528 - accuracy: 0.9059 - val_loss: 0.3044 - val_accuracy: 0.8965\n",
            "Epoch 69/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2511 - accuracy: 0.9068 - val_loss: 0.3212 - val_accuracy: 0.8927\n",
            "Epoch 70/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2500 - accuracy: 0.9084 - val_loss: 0.3139 - val_accuracy: 0.8921\n",
            "Epoch 71/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2537 - accuracy: 0.9067 - val_loss: 0.3181 - val_accuracy: 0.8947\n",
            "Epoch 72/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2505 - accuracy: 0.9084 - val_loss: 0.3125 - val_accuracy: 0.8935\n",
            "Epoch 73/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2467 - accuracy: 0.9077 - val_loss: 0.3254 - val_accuracy: 0.8933\n",
            "Epoch 74/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2433 - accuracy: 0.9095 - val_loss: 0.3291 - val_accuracy: 0.8931\n",
            "Epoch 75/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2447 - accuracy: 0.9089 - val_loss: 0.3189 - val_accuracy: 0.8947\n",
            "Epoch 76/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2496 - accuracy: 0.9075 - val_loss: 0.3228 - val_accuracy: 0.8960\n",
            "Epoch 77/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2452 - accuracy: 0.9081 - val_loss: 0.3255 - val_accuracy: 0.8924\n",
            "Epoch 78/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2432 - accuracy: 0.9094 - val_loss: 0.3179 - val_accuracy: 0.8936\n",
            "Epoch 79/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2406 - accuracy: 0.9102 - val_loss: 0.3293 - val_accuracy: 0.8903\n",
            "Epoch 80/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2460 - accuracy: 0.9096 - val_loss: 0.3291 - val_accuracy: 0.8947\n",
            "Epoch 81/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2439 - accuracy: 0.9086 - val_loss: 0.3252 - val_accuracy: 0.8947\n",
            "Epoch 82/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2406 - accuracy: 0.9110 - val_loss: 0.3220 - val_accuracy: 0.8945\n",
            "Epoch 83/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2382 - accuracy: 0.9130 - val_loss: 0.3236 - val_accuracy: 0.8950\n",
            "Epoch 84/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2422 - accuracy: 0.9103 - val_loss: 0.3210 - val_accuracy: 0.8959\n",
            "Epoch 85/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2407 - accuracy: 0.9124 - val_loss: 0.3198 - val_accuracy: 0.8972\n",
            "Epoch 86/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2400 - accuracy: 0.9119 - val_loss: 0.3278 - val_accuracy: 0.8950\n",
            "Epoch 87/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2400 - accuracy: 0.9115 - val_loss: 0.3203 - val_accuracy: 0.8965\n",
            "Epoch 88/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2338 - accuracy: 0.9133 - val_loss: 0.3310 - val_accuracy: 0.8967\n",
            "Epoch 89/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2333 - accuracy: 0.9141 - val_loss: 0.3292 - val_accuracy: 0.8950\n",
            "Epoch 90/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2363 - accuracy: 0.9133 - val_loss: 0.3242 - val_accuracy: 0.8957\n",
            "Epoch 91/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2327 - accuracy: 0.9144 - val_loss: 0.3349 - val_accuracy: 0.8952\n",
            "Epoch 92/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2387 - accuracy: 0.9110 - val_loss: 0.3253 - val_accuracy: 0.8963\n",
            "Epoch 93/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2322 - accuracy: 0.9142 - val_loss: 0.3410 - val_accuracy: 0.8945\n",
            "Epoch 94/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2347 - accuracy: 0.9126 - val_loss: 0.3330 - val_accuracy: 0.8929\n",
            "Epoch 95/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2350 - accuracy: 0.9135 - val_loss: 0.3231 - val_accuracy: 0.8980\n",
            "Epoch 96/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2310 - accuracy: 0.9147 - val_loss: 0.3184 - val_accuracy: 0.8938\n",
            "Epoch 97/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2332 - accuracy: 0.9138 - val_loss: 0.3226 - val_accuracy: 0.8956\n",
            "Epoch 98/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2321 - accuracy: 0.9138 - val_loss: 0.3410 - val_accuracy: 0.8938\n",
            "Epoch 99/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2309 - accuracy: 0.9144 - val_loss: 0.3372 - val_accuracy: 0.8967\n",
            "Epoch 100/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2315 - accuracy: 0.9143 - val_loss: 0.3340 - val_accuracy: 0.8953\n",
            "Epoch 101/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2345 - accuracy: 0.9139 - val_loss: 0.3242 - val_accuracy: 0.8963\n",
            "Epoch 102/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2305 - accuracy: 0.9150 - val_loss: 0.3409 - val_accuracy: 0.8938\n",
            "Epoch 103/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2278 - accuracy: 0.9153 - val_loss: 0.3425 - val_accuracy: 0.8954\n",
            "Epoch 104/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2312 - accuracy: 0.9139 - val_loss: 0.3282 - val_accuracy: 0.8948\n",
            "Epoch 105/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2265 - accuracy: 0.9173 - val_loss: 0.3291 - val_accuracy: 0.8943\n",
            "Epoch 106/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2262 - accuracy: 0.9153 - val_loss: 0.3381 - val_accuracy: 0.8981\n",
            "Epoch 107/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2275 - accuracy: 0.9165 - val_loss: 0.3362 - val_accuracy: 0.8959\n",
            "Epoch 108/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2261 - accuracy: 0.9151 - val_loss: 0.3401 - val_accuracy: 0.8930\n",
            "Epoch 109/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2213 - accuracy: 0.9164 - val_loss: 0.3273 - val_accuracy: 0.8985\n",
            "Epoch 110/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2257 - accuracy: 0.9172 - val_loss: 0.3346 - val_accuracy: 0.8976\n",
            "Epoch 111/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2246 - accuracy: 0.9180 - val_loss: 0.3330 - val_accuracy: 0.8971\n",
            "Epoch 112/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2213 - accuracy: 0.9178 - val_loss: 0.3377 - val_accuracy: 0.8958\n",
            "Epoch 113/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2207 - accuracy: 0.9181 - val_loss: 0.3390 - val_accuracy: 0.8928\n",
            "Epoch 114/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2236 - accuracy: 0.9179 - val_loss: 0.3344 - val_accuracy: 0.8971\n",
            "Epoch 115/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2169 - accuracy: 0.9191 - val_loss: 0.3452 - val_accuracy: 0.8926\n",
            "Epoch 116/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2189 - accuracy: 0.9175 - val_loss: 0.3480 - val_accuracy: 0.8946\n",
            "Epoch 117/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2175 - accuracy: 0.9184 - val_loss: 0.3466 - val_accuracy: 0.8971\n",
            "Epoch 118/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2202 - accuracy: 0.9187 - val_loss: 0.3410 - val_accuracy: 0.8969\n",
            "Epoch 119/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2129 - accuracy: 0.9222 - val_loss: 0.3400 - val_accuracy: 0.9002\n",
            "Epoch 120/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2197 - accuracy: 0.9196 - val_loss: 0.3469 - val_accuracy: 0.8953\n",
            "Epoch 121/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2152 - accuracy: 0.9210 - val_loss: 0.3426 - val_accuracy: 0.8954\n",
            "Epoch 122/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2153 - accuracy: 0.9209 - val_loss: 0.3481 - val_accuracy: 0.8947\n",
            "Epoch 123/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2195 - accuracy: 0.9198 - val_loss: 0.3385 - val_accuracy: 0.8982\n",
            "Epoch 124/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2204 - accuracy: 0.9178 - val_loss: 0.3436 - val_accuracy: 0.8933\n",
            "Epoch 125/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2139 - accuracy: 0.9198 - val_loss: 0.3381 - val_accuracy: 0.8969\n",
            "Epoch 126/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2141 - accuracy: 0.9208 - val_loss: 0.3532 - val_accuracy: 0.8992\n",
            "Epoch 127/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2127 - accuracy: 0.9221 - val_loss: 0.3573 - val_accuracy: 0.8962\n",
            "Epoch 128/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2134 - accuracy: 0.9201 - val_loss: 0.3442 - val_accuracy: 0.8964\n",
            "Epoch 129/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2112 - accuracy: 0.9221 - val_loss: 0.3596 - val_accuracy: 0.8953\n",
            "Epoch 130/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2141 - accuracy: 0.9209 - val_loss: 0.3518 - val_accuracy: 0.8935\n",
            "Epoch 131/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2086 - accuracy: 0.9221 - val_loss: 0.3530 - val_accuracy: 0.8978\n",
            "Epoch 132/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2152 - accuracy: 0.9217 - val_loss: 0.3520 - val_accuracy: 0.8996\n",
            "Epoch 133/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2115 - accuracy: 0.9216 - val_loss: 0.3505 - val_accuracy: 0.8953\n",
            "Epoch 134/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2136 - accuracy: 0.9215 - val_loss: 0.3552 - val_accuracy: 0.8977\n",
            "Epoch 135/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2099 - accuracy: 0.9214 - val_loss: 0.3535 - val_accuracy: 0.8957\n",
            "Epoch 136/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2120 - accuracy: 0.9235 - val_loss: 0.3592 - val_accuracy: 0.8979\n",
            "Epoch 137/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2083 - accuracy: 0.9235 - val_loss: 0.3513 - val_accuracy: 0.8979\n",
            "Epoch 138/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2044 - accuracy: 0.9232 - val_loss: 0.3511 - val_accuracy: 0.8944\n",
            "Epoch 139/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2096 - accuracy: 0.9230 - val_loss: 0.3626 - val_accuracy: 0.8964\n",
            "Epoch 140/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2124 - accuracy: 0.9223 - val_loss: 0.3558 - val_accuracy: 0.8943\n",
            "Epoch 141/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2102 - accuracy: 0.9222 - val_loss: 0.3612 - val_accuracy: 0.8930\n",
            "Epoch 142/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2075 - accuracy: 0.9236 - val_loss: 0.3645 - val_accuracy: 0.8933\n",
            "Epoch 143/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2032 - accuracy: 0.9250 - val_loss: 0.3737 - val_accuracy: 0.8910\n",
            "Epoch 144/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2062 - accuracy: 0.9241 - val_loss: 0.3483 - val_accuracy: 0.8981\n",
            "Epoch 145/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2051 - accuracy: 0.9252 - val_loss: 0.3582 - val_accuracy: 0.8982\n",
            "Epoch 146/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2075 - accuracy: 0.9240 - val_loss: 0.3603 - val_accuracy: 0.8989\n",
            "Epoch 147/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2025 - accuracy: 0.9245 - val_loss: 0.3607 - val_accuracy: 0.8976\n",
            "Epoch 148/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1989 - accuracy: 0.9251 - val_loss: 0.3550 - val_accuracy: 0.8939\n",
            "Epoch 149/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2044 - accuracy: 0.9255 - val_loss: 0.3610 - val_accuracy: 0.8947\n",
            "Epoch 150/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2072 - accuracy: 0.9236 - val_loss: 0.3506 - val_accuracy: 0.8981\n",
            "Epoch 151/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2062 - accuracy: 0.9251 - val_loss: 0.3582 - val_accuracy: 0.8942\n",
            "Epoch 152/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2026 - accuracy: 0.9252 - val_loss: 0.3624 - val_accuracy: 0.8977\n",
            "Epoch 153/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2060 - accuracy: 0.9243 - val_loss: 0.3739 - val_accuracy: 0.8955\n",
            "Epoch 154/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2015 - accuracy: 0.9247 - val_loss: 0.3750 - val_accuracy: 0.8956\n",
            "Epoch 155/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2009 - accuracy: 0.9255 - val_loss: 0.3647 - val_accuracy: 0.8965\n",
            "Epoch 156/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2018 - accuracy: 0.9251 - val_loss: 0.3587 - val_accuracy: 0.8975\n",
            "Epoch 157/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2058 - accuracy: 0.9249 - val_loss: 0.3573 - val_accuracy: 0.8989\n",
            "Epoch 158/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2011 - accuracy: 0.9268 - val_loss: 0.3615 - val_accuracy: 0.8967\n",
            "Epoch 159/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2019 - accuracy: 0.9265 - val_loss: 0.3645 - val_accuracy: 0.8949\n",
            "Epoch 160/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2010 - accuracy: 0.9264 - val_loss: 0.3697 - val_accuracy: 0.8970\n",
            "Epoch 161/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1994 - accuracy: 0.9262 - val_loss: 0.3622 - val_accuracy: 0.8959\n",
            "Epoch 162/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1980 - accuracy: 0.9266 - val_loss: 0.3654 - val_accuracy: 0.8976\n",
            "Epoch 163/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2047 - accuracy: 0.9247 - val_loss: 0.3556 - val_accuracy: 0.8961\n",
            "Epoch 164/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1968 - accuracy: 0.9269 - val_loss: 0.3739 - val_accuracy: 0.8969\n",
            "Epoch 165/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1985 - accuracy: 0.9262 - val_loss: 0.3801 - val_accuracy: 0.8907\n",
            "Epoch 166/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2022 - accuracy: 0.9253 - val_loss: 0.3730 - val_accuracy: 0.8962\n",
            "Epoch 167/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1939 - accuracy: 0.9271 - val_loss: 0.3814 - val_accuracy: 0.8991\n",
            "Epoch 168/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1937 - accuracy: 0.9293 - val_loss: 0.3674 - val_accuracy: 0.8938\n",
            "Epoch 169/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1936 - accuracy: 0.9281 - val_loss: 0.3971 - val_accuracy: 0.8942\n",
            "Epoch 170/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1946 - accuracy: 0.9279 - val_loss: 0.3924 - val_accuracy: 0.8981\n",
            "Epoch 171/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1963 - accuracy: 0.9281 - val_loss: 0.3707 - val_accuracy: 0.8972\n",
            "Epoch 172/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1969 - accuracy: 0.9265 - val_loss: 0.3821 - val_accuracy: 0.8949\n",
            "Epoch 173/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1994 - accuracy: 0.9268 - val_loss: 0.3700 - val_accuracy: 0.8971\n",
            "Epoch 174/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1913 - accuracy: 0.9302 - val_loss: 0.3817 - val_accuracy: 0.8975\n",
            "Epoch 175/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1965 - accuracy: 0.9282 - val_loss: 0.3784 - val_accuracy: 0.8971\n",
            "Epoch 176/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1918 - accuracy: 0.9296 - val_loss: 0.3819 - val_accuracy: 0.8930\n",
            "Epoch 177/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1923 - accuracy: 0.9275 - val_loss: 0.3770 - val_accuracy: 0.8993\n",
            "Epoch 178/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1982 - accuracy: 0.9263 - val_loss: 0.3680 - val_accuracy: 0.8963\n",
            "Epoch 179/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1983 - accuracy: 0.9273 - val_loss: 0.3748 - val_accuracy: 0.8947\n",
            "Epoch 180/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1879 - accuracy: 0.9301 - val_loss: 0.4047 - val_accuracy: 0.8982\n",
            "Epoch 181/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.9285 - val_loss: 0.3931 - val_accuracy: 0.8971\n",
            "Epoch 182/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1915 - accuracy: 0.9281 - val_loss: 0.3980 - val_accuracy: 0.8953\n",
            "Epoch 183/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1947 - accuracy: 0.9291 - val_loss: 0.3840 - val_accuracy: 0.8964\n",
            "Epoch 184/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1918 - accuracy: 0.9294 - val_loss: 0.3837 - val_accuracy: 0.8933\n",
            "Epoch 185/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1918 - accuracy: 0.9298 - val_loss: 0.3711 - val_accuracy: 0.8947\n",
            "Epoch 186/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1913 - accuracy: 0.9297 - val_loss: 0.3931 - val_accuracy: 0.8942\n",
            "Epoch 187/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1960 - accuracy: 0.9275 - val_loss: 0.3994 - val_accuracy: 0.8957\n",
            "Epoch 188/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1872 - accuracy: 0.9311 - val_loss: 0.3961 - val_accuracy: 0.8943\n",
            "Epoch 189/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1835 - accuracy: 0.9320 - val_loss: 0.3951 - val_accuracy: 0.8917\n",
            "Epoch 190/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1937 - accuracy: 0.9297 - val_loss: 0.3957 - val_accuracy: 0.8964\n",
            "Epoch 191/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1861 - accuracy: 0.9301 - val_loss: 0.3937 - val_accuracy: 0.8953\n",
            "Epoch 192/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1870 - accuracy: 0.9307 - val_loss: 0.4078 - val_accuracy: 0.8954\n",
            "Epoch 193/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1875 - accuracy: 0.9297 - val_loss: 0.3847 - val_accuracy: 0.8997\n",
            "Epoch 194/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1927 - accuracy: 0.9304 - val_loss: 0.3833 - val_accuracy: 0.8956\n",
            "Epoch 195/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1862 - accuracy: 0.9299 - val_loss: 0.3871 - val_accuracy: 0.8982\n",
            "Epoch 196/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1825 - accuracy: 0.9321 - val_loss: 0.4172 - val_accuracy: 0.8936\n",
            "Epoch 197/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1889 - accuracy: 0.9296 - val_loss: 0.4082 - val_accuracy: 0.8979\n",
            "Epoch 198/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1855 - accuracy: 0.9323 - val_loss: 0.4003 - val_accuracy: 0.8957\n",
            "Epoch 199/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1868 - accuracy: 0.9309 - val_loss: 0.3985 - val_accuracy: 0.8986\n",
            "Epoch 200/200\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1866 - accuracy: 0.9318 - val_loss: 0.4207 - val_accuracy: 0.8944\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AmM208NPbyP",
        "outputId": "e3394e82-cb80-4789-f976-141feedcaa8c"
      },
      "source": [
        "# Checking model summary\n",
        "model_8.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"mlp8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_layer1 (Dense)         (None, 392)               307720    \n",
            "_________________________________________________________________\n",
            "dropout_layer1 (Dropout)     (None, 392)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer2 (Dense)         (None, 196)               77028     \n",
            "_________________________________________________________________\n",
            "dropout_layer2 (Dropout)     (None, 196)               0         \n",
            "_________________________________________________________________\n",
            "dense_layer3 (Dense)         (None, 10)                1970      \n",
            "=================================================================\n",
            "Total params: 386,718\n",
            "Trainable params: 386,718\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe2_ADmMB0ol",
        "outputId": "2978849c-cf62-457c-e2be-858a7c182e1a"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model_8.evaluate(X_test_norm, y_test_cat, batch_size= 64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8908\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4713849127292633, 0.8907999992370605]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMUTzS8NPh5T"
      },
      "source": [
        "After increasing epochs there is not much improvement in validation and testing accuracy but training accuracy has been increased. Also testing loss is higher than our previous model. So, it seems the model is gradually overfitting. So, we'll use model_7 as our final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvTS5g2ntAnq"
      },
      "source": [
        "## Final model details"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzllgHko3FSO"
      },
      "source": [
        "Model 8 is giving better result and next it can be seen that with increase in number of epochs, started to overfit the model. So, model 8 is our final model with testing accuracy of .89"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdCqzMXPs2LS",
        "outputId": "7ba73770-c749-4473-b532-80ccf9ba4cc1"
      },
      "source": [
        "# Evaluating the model on test dataset\n",
        "model_7.evaluate(X_test_norm, y_test_cat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3709 - accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3709065616130829, 0.8899999856948853]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx7B2wGF_Pm1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "7456ad80-8391-41a5-d67f-baa4461287bb"
      },
      "source": [
        "# Plotting accuracy for different epochs\n",
        "plt.figure(figsize= [8,5])\n",
        "plt.plot(history_7.history['accuracy'])\n",
        "plt.plot(history_7.history['val_accuracy'])\n",
        "plt.title('Plot for model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a-r1uUlAKJd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "08857a21-b7bf-4273-ca98-fb74b2fe6418"
      },
      "source": [
        "# Plotting loss for different epochs\n",
        "plt.figure(figsize= [8,5])\n",
        "plt.plot(history_7.history['loss'])\n",
        "plt.plot(history_7.history['val_loss'])\n",
        "plt.title('Plot for model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eib7GeoG4-nB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a8f730-611f-45b3-9286-b6ab345c1f59"
      },
      "source": [
        "# Final model parameters\n",
        "model_7.get_config()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 784),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'dense_layer1_input',\n",
              "    'ragged': False,\n",
              "    'sparse': False}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'batch_input_shape': (None, 784),\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_layer1',\n",
              "    'trainable': True,\n",
              "    'units': 392,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_layer1',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.5,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'relu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'HeNormal', 'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_layer2',\n",
              "    'trainable': True,\n",
              "    'units': 196,\n",
              "    'use_bias': True}},\n",
              "  {'class_name': 'Dropout',\n",
              "   'config': {'dtype': 'float32',\n",
              "    'name': 'dropout_layer2',\n",
              "    'noise_shape': None,\n",
              "    'rate': 0.5,\n",
              "    'seed': None,\n",
              "    'trainable': True}},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'softmax',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'dense_layer3',\n",
              "    'trainable': True,\n",
              "    'units': 10,\n",
              "    'use_bias': True}}],\n",
              " 'name': 'mlp7'}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSkrvmpWtWqQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}